{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kartikeyahl/MS_analysis/blob/main/WFOLatestOT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "S6DZ4_-nAQcH"
      },
      "outputs": [],
      "source": [
        "# # Importing the libraries\n",
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "# import matplotlib.pyplot as plt\n",
        "# import seaborn as sns\n",
        "# from datetime import datetime,timedelta\n",
        "# import math\n",
        "# import concurrent.futures as ft\n",
        "# import multiprocessing\n",
        "# import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install xlsxwriter\n",
        "!pip install xlutils"
      ],
      "metadata": {
        "id": "I3wYDBoSevev",
        "outputId": "432d34ba-389d-4d20-b575-41bcb8520167",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting xlsxwriter\n",
            "  Downloading XlsxWriter-3.1.0-py3-none-any.whl (152 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.7/152.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xlsxwriter\n",
            "Successfully installed xlsxwriter-3.1.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting xlutils\n",
            "  Downloading xlutils-2.0.0-py2.py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.1/55.1 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: xlrd>=0.7.2 in /usr/local/lib/python3.9/dist-packages (from xlutils) (2.0.1)\n",
            "Collecting xlwt>=0.7.4\n",
            "  Downloading xlwt-1.3.0-py2.py3-none-any.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.0/100.0 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xlwt, xlutils\n",
            "Successfully installed xlutils-2.0.0 xlwt-1.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import random\n",
        "from tkinter import Label, filedialog, font, messagebox, ttk\n",
        "import tkinter as tk\n",
        "import functools\n",
        "fp = functools.partial\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tkinter import *\n",
        "from tkinter.ttk import Style, Treeview\n",
        "from datetime import datetime,timedelta, date\n",
        "import math\n",
        "from tkinter import ttk\n",
        "\n",
        "from sys import platform\n",
        "import matplotlib.pyplot as plt\n",
        "import concurrent.futures as ft\n",
        "import multiprocessing\n",
        "from openpyxl import Workbook\n",
        "import xlsxwriter\n",
        "import os\n",
        "from cryptography.fernet import Fernet\n",
        "import base64"
      ],
      "metadata": {
        "id": "JlF4tPUw-e-O"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the excel\n",
        "def loadData():\n",
        "  global dataset,dataset2,dataset3\n",
        "  # !unzip punch_short.xlsx\n",
        "  dataset = pd.read_excel('punch_short.xlsx',parse_dates=['Date'],\n",
        "      date_parser=lambda x: pd.to_datetime(x, format='%Y%m%d'))\n",
        "  dataset2=pd.read_excel('Master Data.xlsx')\n",
        "  dataset3=pd.read_excel('Shift_Timings.xlsx')\n",
        "\n",
        "with ft.ThreadPoolExecutor() as executor:\n",
        "  executor.submit(loadData)"
      ],
      "metadata": {
        "id": "gUshG7J-qrDE"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.rename(columns={'IN/OUT': 'IN_OUT'}, inplace=True)\n",
        "\n",
        "#Droping rows that conatain 1 in 'IN_OUT' column\n",
        "dataset=dataset[dataset.IN_OUT!=1]\n",
        "dataset2=dataset2[dataset2.Status!='Withdrawn']\n",
        "\n",
        "dataset['Date'] = pd.to_datetime(dataset['Date'], errors='coerce')\n",
        "dataset.dropna(inplace=True)\n",
        "\n",
        "a1=str(dataset.iloc[0]['Date'])\n",
        "a2=str(dataset.iloc[-1]['Date'])\n",
        "d1 = datetime.strptime(a1[0:10], \"%Y-%m-%d\")\n",
        "d2 = datetime.strptime(a2[0:10], \"%Y-%m-%d\")\n",
        "date_diff = abs((d2 - d1).days)+1  "
      ],
      "metadata": {
        "id": "-tDeG-h12Awc",
        "outputId": "b10f512d-2dae-4e20-f5b4-27a4fa86d358",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-6341b5f4387b>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  dataset['Date'] = pd.to_datetime(dataset['Date'], errors='coerce')\n",
            "<ipython-input-5-6341b5f4387b>:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  dataset.dropna(inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculating and appending Punch time difference for each employee with the corresponding E.Code into dataframe (l)\n",
        "l_shift=[]\n",
        "for i in range(len(dataset3)):\n",
        "    x_=str(int(dataset3.iloc[i]['Start']))\n",
        "    y_=str(int(dataset3.iloc[i]['End']))\n",
        "\n",
        "    if len(x_)<=5:\n",
        "        x_=x_.zfill(6)\n",
        "    if len(y_)<=5:\n",
        "        y_=y_.zfill(6)\n",
        "\n",
        "    x_ = datetime.strptime(x_, \"%H%M%S\")\n",
        "    x_.strftime(\"%I:%M %p\")\n",
        "    y_ = datetime.strptime(y_, \"%H%M%S\")\n",
        "    y_.strftime(\"%I:%M %p\")\n",
        "\n",
        "    presentday = pd.to_datetime('20221001', errors='coerce')\n",
        "    tomorrow = pd.to_datetime('20221002', errors='coerce')\n",
        "    if dataset3.iloc[i]['End date']=='same':\n",
        "        l_shift.append([datetime.combine(presentday, y_.time()) - datetime.combine(presentday, x_.time())])\n",
        "    else:\n",
        "        l_shift.append([datetime.combine(tomorrow, y_.time()) - datetime.combine(presentday, x_.time())])    \n",
        "\n",
        "\n",
        "\n",
        "#Calculating and appending Punch time difference for each employee with the corresponding E.Code into dataframe (l)\n",
        "\n",
        "l=[]\n",
        "for i in range(len(dataset)-1):\n",
        "    j=i+1\n",
        "    x=str(int(dataset.iloc[i]['Time']))\n",
        "    y=str(int(dataset.iloc[j]['Time']))\n",
        "    if len(x)<=5:\n",
        "        x=x.zfill(6)\n",
        "    if len(y)<=5:\n",
        "        y=y.zfill(6)\n",
        "\n",
        "    x = datetime.strptime(x, \"%H%M%S\")\n",
        "    x.strftime(\"%I:%M %p\")\n",
        "    y = datetime.strptime(y, \"%H%M%S\")\n",
        "    y.strftime(\"%I:%M %p\")\n",
        "    l.append([dataset.iloc[i]['E.Code'], dataset.iloc[i]['Date'].date(), dataset.iloc[i]['IN_OUT'], int(dataset.iloc[i]['Time']), datetime.combine(dataset.iloc[j]['Date'], y.time()) - datetime.combine(dataset.iloc[i]['Date'], x.time()) if dataset.iloc[i]['Location']!= 'Head Office - Manesar' else datetime.combine(date.today(), y.time()) - datetime.combine(date.today(), x.time()),dataset.iloc[i]['Location']])  \n",
        "    i=i+2\n",
        "    \n",
        "\n",
        "print(l2)\n",
        "\n",
        "#Replacing \":\" with \".\" and getting upto 2 decimal places in Time to make mathematical operations feasible on i\n",
        "for i in range(len(l)):\n",
        "    l[i][4] = l[i][4].__str__().replace(\":\",\".\")\n",
        "    s=l[i][4]\n",
        "    l[i][4]=s[0:-3]\n",
        "\n",
        "for i in range(len(l_shift)):\n",
        "    l_shift[i][0] = l_shift[i][0].__str__().replace(\":\",\".\")\n",
        "    s=l_shift[i][0]\n",
        "    l_shift[i][0]=float(s[0:-3])\n",
        "\n",
        "data3= pd.DataFrame(l_shift,columns=['Difference'])\n",
        "dataset3= pd.concat([dataset3,data3],axis=1)\n",
        "\n",
        "#Removing redundant rows and storing in new data-structure\n",
        "l2=[]\n",
        "for i in range(len(l)):\n",
        "    if 'P20' not in str(l[i][2]):\n",
        "        l2.append(l[i])\n",
        "\n",
        "for i in range(len(l2)):\n",
        "    if 'd' in l2[i][4]:\n",
        "        s=l2[i][4]\n",
        "        s=float(s[7:len(s)])\n",
        "        l2[i][4]=24+s\n",
        "\n",
        "#Converting string type to float for Time column\n",
        "for i in range(len(l2)):\n",
        "    try:\n",
        "        l2[i][4]=float(\"{:.2f}\".format(float(l2[i][4])))\n",
        "    except:                      \n",
        "        pass\n",
        "\n",
        "for i in range(len(l2)):\n",
        "    try:\n",
        "        l2[i][4]=float(\"{:.2f}\".format(float(l2[i][4])))\n",
        "    except:                      \n",
        "        pass\n",
        "\n",
        "l3=[]\n",
        "for i in range(len(l2)):  \n",
        "    frac, whole = math.modf(l2[i][4])\n",
        "    mins=int(whole*60+frac*100)\n",
        "\n",
        "    try:\n",
        "        #1F A-Shift\n",
        "        if (dataset3.iloc[0]['Start']+1500)>=l2[i][3]>=(dataset3.iloc[0]['Start']-3000) and '1F' in l2[i][5]:\n",
        "            frac1, whole1 = math.modf(dataset3.iloc[0]['Difference'])\n",
        "            mins_dif=int(whole1*60+frac1*100)\n",
        "            mins_dif+=30\n",
        "            if mins>mins_dif:\n",
        "                mins=mins-mins_dif\n",
        "                hours=mins//60\n",
        "                minutes=mins%60\n",
        "                if minutes<10:\n",
        "                    ot_time = float(\"{}.0{}\".format(hours, minutes))\n",
        "                elif minutes%10==0:\n",
        "                    ot_time = float(\"{}.{}0\".format(hours, minutes))\n",
        "                else:\n",
        "                    ot_time = float(\"{}.{}\".format(hours, minutes))\n",
        "                l2[i]=l2[i][:-1]\n",
        "                l2[i].append(ot_time)\n",
        "                l3.append(l2[i])\n",
        "\n",
        "        #1F B-Shift\n",
        "        elif (dataset3.iloc[1]['Start']+1500)>=l2[i][3]>=(dataset3.iloc[1]['Start']-3000) and '1F' in l2[i][5]:\n",
        "            frac1, whole1 = math.modf(dataset3.iloc[1]['Difference'])\n",
        "            mins_dif=int(whole1*60+frac1*100)\n",
        "            mins_dif+=30\n",
        "            if mins>mins_dif:\n",
        "                mins=mins-mins_dif\n",
        "                hours=mins//60\n",
        "                minutes=mins%60\n",
        "                if minutes<10:\n",
        "                    ot_time = float(\"{}.0{}\".format(hours, minutes))\n",
        "                elif minutes%10==0:\n",
        "                    ot_time = float(\"{}.{}0\".format(hours, minutes))\n",
        "                else:\n",
        "                    ot_time = float(\"{}.{}\".format(hours, minutes))\n",
        "                l2[i]=l2[i][:-1]\n",
        "                l2[i].append(ot_time)\n",
        "                l3.append(l2[i])\n",
        "\n",
        "        #1F C-Shift\n",
        "        elif (dataset3.iloc[2]['Start']+1500)>=l2[i][3]>=(dataset3.iloc[2]['Start']-3000) and '1F' in l2[i][5]:\n",
        "            frac1, whole1 = math.modf(dataset3.iloc[2]['Difference'])\n",
        "            mins_dif=int(whole1*60+frac1*100)\n",
        "            mins_dif+=30\n",
        "            if mins>mins_dif:\n",
        "                mins=mins-mins_dif\n",
        "                hours=mins//60\n",
        "                minutes=mins%60\n",
        "                if minutes<10:\n",
        "                    ot_time = float(\"{}.0{}\".format(hours, minutes))\n",
        "                elif minutes%10==0:\n",
        "                    ot_time = float(\"{}.{}0\".format(hours, minutes))\n",
        "                else:\n",
        "                    ot_time = float(\"{}.{}\".format(hours, minutes))\n",
        "                l2[i]=l2[i][:-1]\n",
        "                l2[i].append(ot_time)\n",
        "                l3.append(l2[i])\n",
        "\n",
        "        #HO G-Shift\n",
        "        elif (dataset3.iloc[15]['Start']+10000)>=l2[i][3]>=(dataset3.iloc[15]['Start']-10000) and 'Head' in l2[i][5]:\n",
        "            frac1, whole1 = math.modf(dataset3.iloc[15]['Difference'])\n",
        "            mins_dif=int(whole1*60+frac1*100)\n",
        "            mins_dif+=30\n",
        "            if mins>mins_dif:\n",
        "                mins=mins-mins_dif\n",
        "                hours=mins//60\n",
        "                minutes=mins%60\n",
        "                if minutes<10:\n",
        "                    ot_time = float(\"{}.0{}\".format(hours, minutes))\n",
        "                elif minutes%10==0:\n",
        "                    ot_time = float(\"{}.{}0\".format(hours, minutes))\n",
        "                else:\n",
        "                    ot_time = float(\"{}.{}\".format(hours, minutes))\n",
        "                l2[i]=l2[i][:-1]\n",
        "                l2[i].append(ot_time)\n",
        "                l3.append(l2[i])\n",
        "\n",
        "        #2F A-Shift\n",
        "        elif (dataset3.iloc[3]['Start']+1500)>=l2[i][3]>=(dataset3.iloc[3]['Start']-3000) and '2F' in l2[i][5]:\n",
        "            frac1, whole1 = math.modf(dataset3.iloc[3]['Difference'])\n",
        "            mins_dif=int(whole1*60+frac1*100)\n",
        "            mins_dif+=30\n",
        "            if mins>mins_dif:\n",
        "                mins=mins-mins_dif\n",
        "                hours=mins//60\n",
        "                minutes=mins%60\n",
        "                if minutes<10:\n",
        "                    ot_time = float(\"{}.0{}\".format(hours, minutes))\n",
        "                elif minutes%10==0:\n",
        "                    ot_time = float(\"{}.{}0\".format(hours, minutes))\n",
        "                else:\n",
        "                    ot_time = float(\"{}.{}\".format(hours, minutes))\n",
        "                l2[i]=l2[i][:-1]\n",
        "                l2[i].append(ot_time)\n",
        "                l3.append(l2[i])\n",
        "\n",
        "        #2F B4-Shift\n",
        "        elif (dataset3.iloc[4]['Start']+1500)>=l2[i][3]>=(dataset3.iloc[4]['Start']-3000) and '2F' in l2[i][5]:\n",
        "            frac1, whole1 = math.modf(dataset3.iloc[4]['Difference'])\n",
        "            mins_dif=int(whole1*60+frac1*100)\n",
        "            mins_dif+=30\n",
        "            if mins>mins_dif:\n",
        "                mins=mins-mins_dif\n",
        "                hours=mins//60\n",
        "                minutes=mins%60\n",
        "                if minutes<10:\n",
        "                    ot_time = float(\"{}.0{}\".format(hours, minutes))\n",
        "                elif minutes%10==0:\n",
        "                    ot_time = float(\"{}.{}0\".format(hours, minutes))\n",
        "                else:\n",
        "                    ot_time = float(\"{}.{}\".format(hours, minutes))\n",
        "                l2[i]=l2[i][:-1]\n",
        "                l2[i].append(ot_time)\n",
        "                l3.append(l2[i])\n",
        "\n",
        "        #2F C-Shift\n",
        "        elif (dataset3.iloc[5]['Start']+1500)>=l2[i][3]>=(dataset3.iloc[5]['Start']-3000) and '2F' in l2[i][5]:\n",
        "            frac1, whole1 = math.modf(dataset3.iloc[5]['Difference'])\n",
        "            mins_dif=int(whole1*60+frac1*100)\n",
        "            mins_dif+=30\n",
        "            if mins>mins_dif:\n",
        "                mins=mins-mins_dif\n",
        "                hours=mins//60\n",
        "                minutes=mins%60\n",
        "                if minutes<10:\n",
        "                    ot_time = float(\"{}.0{}\".format(hours, minutes))\n",
        "                elif minutes%10==0:\n",
        "                    ot_time = float(\"{}.{}0\".format(hours, minutes))\n",
        "                else:\n",
        "                    ot_time = float(\"{}.{}\".format(hours, minutes))\n",
        "                l2[i]=l2[i][:-1]\n",
        "                l2[i].append(ot_time)\n",
        "                l3.append(l2[i])\n",
        "\n",
        "        #2F G-Shift\n",
        "        elif (dataset3.iloc[6]['Start']+10000)>=l2[i][3]>=(dataset3.iloc[6]['Start']-10000) and '2F' in l2[i][5]:\n",
        "            frac1, whole1 = math.modf(dataset3.iloc[6]['Difference'])\n",
        "            mins_dif=int(whole1*60+frac1*100)\n",
        "            mins_dif+=30\n",
        "            if mins>mins_dif:\n",
        "                mins=mins-mins_dif\n",
        "                hours=mins//60\n",
        "                minutes=mins%60\n",
        "                if minutes<10:\n",
        "                    ot_time = float(\"{}.0{}\".format(hours, minutes))\n",
        "                elif minutes%10==0:\n",
        "                    ot_time = float(\"{}.{}0\".format(hours, minutes))\n",
        "                else:\n",
        "                    ot_time = float(\"{}.{}\".format(hours, minutes))\n",
        "                l2[i]=l2[i][:-1]\n",
        "                l2[i].append(ot_time)\n",
        "                l3.append(l2[i])\n",
        "\n",
        "        #3F A-Shift\n",
        "        elif (dataset3.iloc[7]['Start']+1500)>=l2[i][3]>=(dataset3.iloc[7]['Start']-3000) and '3F' in l2[i][5]:\n",
        "            frac1, whole1 = math.modf(dataset3.iloc[7]['Difference'])\n",
        "            mins_dif=int(whole1*60+frac1*100)\n",
        "            mins_dif+=30\n",
        "            if mins>mins_dif:\n",
        "                mins=mins-mins_dif\n",
        "                hours=mins//60\n",
        "                minutes=mins%60\n",
        "                if minutes<10:\n",
        "                    ot_time = float(\"{}.0{}\".format(hours, minutes))\n",
        "                elif minutes%10==0:\n",
        "                    ot_time = float(\"{}.{}0\".format(hours, minutes))\n",
        "                else:\n",
        "                    ot_time = float(\"{}.{}\".format(hours, minutes))\n",
        "                l2[i]=l2[i][:-1]\n",
        "                l2[i].append(ot_time)\n",
        "                l3.append(l2[i])\n",
        "\n",
        "        #3F B4-Shift\n",
        "        elif (dataset3.iloc[8]['Start']+1500)>=l2[i][3]>=(dataset3.iloc[8]['Start']-3000) and '3F' in l2[i][5]:\n",
        "            frac1, whole1 = math.modf(dataset3.iloc[8]['Difference'])\n",
        "            mins_dif=int(whole1*60+frac1*100)\n",
        "            mins_dif+=30\n",
        "            if mins>mins_dif:\n",
        "                mins=mins-mins_dif\n",
        "                hours=mins//60\n",
        "                minutes=mins%60\n",
        "                if minutes<10:\n",
        "                    ot_time = float(\"{}.0{}\".format(hours, minutes))\n",
        "                elif minutes%10==0:\n",
        "                    ot_time = float(\"{}.{}0\".format(hours, minutes))\n",
        "                else:\n",
        "                    ot_time = float(\"{}.{}\".format(hours, minutes))\n",
        "                l2[i]=l2[i][:-1]\n",
        "                l2[i].append(ot_time)\n",
        "                l3.append(l2[i])\n",
        "\n",
        "        #3F C-Shift\n",
        "        elif (dataset3.iloc[9]['Start']+1500)>=l2[i][3]>=(dataset3.iloc[9]['Start']-3000) and '3F' in l2[i][5]:\n",
        "            frac1, whole1 = math.modf(dataset3.iloc[9]['Difference'])\n",
        "            mins_dif=int(whole1*60+frac1*100)\n",
        "            mins_dif+=30\n",
        "            if mins>mins_dif:\n",
        "                mins=mins-mins_dif\n",
        "                hours=mins//60\n",
        "                minutes=mins%60\n",
        "                if minutes<10:\n",
        "                    ot_time = float(\"{}.0{}\".format(hours, minutes))\n",
        "                elif minutes%10==0:\n",
        "                    ot_time = float(\"{}.{}0\".format(hours, minutes))\n",
        "                else:\n",
        "                    ot_time = float(\"{}.{}\".format(hours, minutes))\n",
        "                l2[i]=l2[i][:-1]\n",
        "                l2[i].append(ot_time)\n",
        "                l3.append(l2[i])\n",
        "\n",
        "        #3F G-Shift\n",
        "        elif (dataset3.iloc[10]['Start']+10000)>=l2[i][3]>=(dataset3.iloc[10]['Start']-1000) and '3F' in l2[i][5]:\n",
        "            frac1, whole1 = math.modf(dataset3.iloc[10]['Difference'])\n",
        "            mins_dif=int(whole1*60+frac1*100)\n",
        "            mins_dif+=30\n",
        "            if mins>mins_dif:\n",
        "                mins=mins-mins_dif\n",
        "                hours=mins//60\n",
        "                minutes=mins%60\n",
        "                if minutes<10:\n",
        "                    ot_time = float(\"{}.0{}\".format(hours, minutes))\n",
        "                elif minutes%10==0:\n",
        "                    ot_time = float(\"{}.{}0\".format(hours, minutes))\n",
        "                else:\n",
        "                    ot_time = float(\"{}.{}\".format(hours, minutes))\n",
        "                l2[i]=l2[i][:-1]\n",
        "                l2[i].append(ot_time)\n",
        "                l3.append(l2[i])\n",
        "\n",
        "        #4F A-Shift\n",
        "        elif (dataset3.iloc[11]['Start']+1500)>=l2[i][3]>=(dataset3.iloc[11]['Start']-3000) and '4F' in l2[i][5]:\n",
        "            frac1, whole1 = math.modf(dataset3.iloc[11]['Difference'])\n",
        "            mins_dif=int(whole1*60+frac1*100)\n",
        "            mins_dif+=30\n",
        "            if mins>mins_dif:\n",
        "                mins=mins-mins_dif\n",
        "                hours=mins//60\n",
        "                minutes=mins%60\n",
        "                if minutes<10:\n",
        "                    ot_time = float(\"{}.0{}\".format(hours, minutes))\n",
        "                elif minutes%10==0:\n",
        "                    ot_time = float(\"{}.{}0\".format(hours, minutes))\n",
        "                else:\n",
        "                    ot_time = float(\"{}.{}\".format(hours, minutes))\n",
        "                l2[i]=l2[i][:-1]\n",
        "                l2[i].append(ot_time)\n",
        "                l3.append(l2[i])\n",
        "\n",
        "        #4F B-Shift\n",
        "        elif (dataset3.iloc[12]['Start']+1500)>=l2[i][3]>=(dataset3.iloc[12]['Start']-3000) and '4F' in l2[i][5]:\n",
        "            frac1, whole1 = math.modf(dataset3.iloc[12]['Difference'])\n",
        "            mins_dif=int(whole1*60+frac1*100)\n",
        "            mins_dif+=30\n",
        "            if mins>mins_dif:\n",
        "                mins=mins-mins_dif\n",
        "                hours=mins//60\n",
        "                minutes=mins%60\n",
        "                if minutes<10:\n",
        "                    ot_time = float(\"{}.0{}\".format(hours, minutes))\n",
        "                elif minutes%10==0:\n",
        "                    ot_time = float(\"{}.{}0\".format(hours, minutes))\n",
        "                else:\n",
        "                    ot_time = float(\"{}.{}\".format(hours, minutes))\n",
        "                l2[i]=l2[i][:-1]\n",
        "                l2[i].append(ot_time)\n",
        "                l3.append(l2[i])\n",
        "\n",
        "        #4F C-Shift\n",
        "        elif (dataset3.iloc[13]['Start']+1500)>=l2[i][3]>=(dataset3.iloc[13]['Start']-3000) and '4F' in l2[i][5]:\n",
        "            frac1, whole1 = math.modf(dataset3.iloc[13]['Difference'])\n",
        "            mins_dif=int(whole1*60+frac1*100)\n",
        "            mins_dif+=30\n",
        "            if mins>mins_dif:\n",
        "                mins=mins-mins_dif\n",
        "                hours=mins//60\n",
        "                minutes=mins%60\n",
        "                if minutes<10:\n",
        "                    ot_time = float(\"{}.0{}\".format(hours, minutes))\n",
        "                elif minutes%10==0:\n",
        "                    ot_time = float(\"{}.{}0\".format(hours, minutes))\n",
        "                else:\n",
        "                    ot_time = float(\"{}.{}\".format(hours, minutes))\n",
        "                l2[i]=l2[i][:-1]\n",
        "                l2[i].append(ot_time)\n",
        "                l3.append(l2[i])\n",
        "\n",
        "        #4F G-Shift\n",
        "        elif (dataset3.iloc[14]['Start']+10000)>=l2[i][3]>=(dataset3.iloc[14]['Start']-10000) and '4F' in l2[i][5]:\n",
        "            frac1, whole1 = math.modf(dataset3.iloc[14]['Difference'])\n",
        "            mins_dif=int(whole1*60+frac1*100)\n",
        "            mins_dif+=30\n",
        "            if mins>mins_dif:\n",
        "                mins=mins-mins_dif\n",
        "                hours=mins//60\n",
        "                minutes=mins%60\n",
        "                if minutes<10:\n",
        "                    ot_time = float(\"{}.0{}\".format(hours, minutes))\n",
        "                elif minutes%10==0:\n",
        "                    ot_time = float(\"{}.{}0\".format(hours, minutes))\n",
        "                else:\n",
        "                    ot_time = float(\"{}.{}\".format(hours, minutes))\n",
        "                l2[i]=l2[i][:-1]\n",
        "                l2[i].append(ot_time)\n",
        "                l3.append(l2[i])\n",
        "\n",
        "    except:\n",
        "        pass\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "                \n",
        "\n",
        "\n",
        "#Removing redundant rows and storing in new data-structure\n",
        "#Removing redundant rows and storing in new data-structure\n",
        "l4=[]\n",
        "for i in range(len(l3)):\n",
        "    if l3[i][5]>0:\n",
        "        l4.append(l3[i])\n",
        "print(\"l4\")\n",
        "print(l4)\n",
        "\n",
        "# Converting 2d list to dataframe to apply CRUD opertations\n",
        "df = pd.DataFrame(l4, columns=['E.Code','Date','IN/OUT','Time','Total Time','OT'])\n",
        "\n",
        "df_copy=df.copy(deep=True)\n",
        "\n",
        "#Droping an unnecesary column\n",
        "df=df.drop(['IN/OUT','Time','Total Time'], axis=1)\n",
        "\n",
        "ll1=[]\n",
        "def binarySearch(arr, l, r, x):\n",
        "\n",
        "    while l <= r:\n",
        "\n",
        "        mid = l + (r - l) // 2\n",
        "\n",
        "        # Check if x is present at mid\n",
        "        if arr[mid] == x:\n",
        "            return mid\n",
        "\n",
        "        # If x is greater, ignore left half\n",
        "        elif arr[mid] < x:\n",
        "            l = mid + 1\n",
        "\n",
        "        # If x is smaller, ignore right half\n",
        "        else:\n",
        "            r = mid - 1\n",
        "\n",
        "    # If we reach here, then the element\n",
        "    # was not present\n",
        "    return -1\n",
        "\n",
        "\n",
        "# Driver Code\n",
        "arr = [int(i) for i in dataset2['E Code']]\n",
        "\n",
        "for i in range(len(df)):\n",
        "    # Function call\n",
        "    result = binarySearch(arr, 0, len(arr)-1, df.iloc[i]['E.Code'])\n",
        "\n",
        "    if result != -1:\n",
        "            ll1.append([dataset2.iloc[result]['Full Name'], dataset2.iloc[result]['Designation'],dataset2.iloc[result]['Location'],dataset2.iloc[result]['Operation'],dataset2.iloc[result]['Division'],dataset2.iloc[result]['Department']])\n",
        "    else:\n",
        "            ll1.append(['NaN','NaN','NaN','NaN','NaN','NaN'])\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "# Converting 2d list to dataframe to apply CRUD opertations\n",
        "dff = pd.DataFrame(ll1, columns=['Full Name','Designation','Location','Operation','Division','Department'])\n",
        "df_final = pd.concat([df['E.Code'], dff, df[['Date','OT']]], axis=1)\n",
        "df_final = df_final[df_final.Location!='NaN']\n",
        "print(\"df\")\n",
        "print(df)\n",
        "#double shift\n",
        "l_double_shift=[]\n",
        "for i in range(len(df_copy)):\n",
        "    if df_copy.iloc[i]['Time']>53000 and df_copy.iloc[i]['Time']<63000:\n",
        "        if df_copy.iloc[i]['Total Time']>=17.50:\n",
        "            l_double_shift.append([df_copy.iloc[i]['E.Code'],df_copy.iloc[i]['Date'],'A-B'])\n",
        "    elif df_copy.iloc[i]['Time']>143000 and df_copy.iloc[i]['Time']<150000:\n",
        "        if df_copy.iloc[i]['Total Time']>=15.50:\n",
        "            l_double_shift.append([df_copy.iloc[i]['E.Code'],df_copy.iloc[i]['Date'],'B-C'])\n",
        "    elif df_copy.iloc[i]['Time']>230000 and df_copy.iloc[i]['Time']<234000:\n",
        "        if df_copy.iloc[i]['Total Time']>=15.50:\n",
        "            l_double_shift.append([df_copy.iloc[i]['E.Code'],df_copy.iloc[i]['Date'],'C-A'])\n",
        "\n",
        "def binarySearch(arr, l, r, x):\n",
        "    while l <= r:\n",
        "\n",
        "        mid = l + (r - l) // 2\n",
        "\n",
        "        # Check if x is present at mid\n",
        "        if arr[mid] == x:\n",
        "            return mid\n",
        "\n",
        "        # If x is greater, ignore left half\n",
        "        elif arr[mid] < x:\n",
        "            l = mid + 1\n",
        "\n",
        "        # If x is smaller, ignore right half\n",
        "        else:\n",
        "            r = mid - 1\n",
        "\n",
        "    # If we reach here, then the element\n",
        "    # was not present\n",
        "    return -1\n",
        "\n",
        "arr = [int(i) for i in dataset2['E Code']]\n",
        "for i in range(len(l_double_shift)):\n",
        "    # Function call\n",
        "    result = binarySearch(arr, 0, len(arr)-1, l_double_shift[i][0])\n",
        "\n",
        "    if result != -1:\n",
        "        l_double_shift[i].append(dataset2.iloc[result]['Full Name'])\n",
        "        l_double_shift[i].append(dataset2.iloc[result]['Designation'])\n",
        "        l_double_shift[i].append(dataset2.iloc[result]['Location'])\n",
        "        l_double_shift[i].append(dataset2.iloc[result]['Operation'])\n",
        "        l_double_shift[i].append(dataset2.iloc[result]['Division'])\n",
        "        l_double_shift[i].append(dataset2.iloc[result]['Department'])\n",
        "    else:\n",
        "        l_double_shift[i].append('NaN')\n",
        "        l_double_shift[i].append('NaN')\n",
        "        l_double_shift[i].append('NaN')\n",
        "        l_double_shift[i].append('NaN')\n",
        "        l_double_shift[i].append('NaN')\n",
        "        l_double_shift[i].append('NaN')\n",
        "\n",
        "l_double_shift = pd.DataFrame(l_double_shift,columns=['E.Code','Date','Double-Shift','Full Name','Designation','Location','Operation','Division','Department'])\n",
        "\n",
        "# function to add value labels\n",
        "def addlabels(x,y):\n",
        "    for i in range(len(x)):\n",
        "        plt.text(i, y[i], y[i], ha = 'center', bbox = dict(facecolor = 'white', alpha =.8))\n",
        "def addlabels2(x,y):\n",
        "    for i in range(len(x)):\n",
        "        plt.text(i, y[i], y[i], ha = 'center')\n",
        "\n",
        "\n",
        "df_final_hr_min=df_final.copy(deep=True)\n",
        "l_time1=[]\n",
        "for i in df_final_hr_min.index:\n",
        "    minutes, hours = math.modf(df_final_hr_min['OT'][i])\n",
        "    minutes*=100\n",
        "    ot_time = \"{:.0f} Hr {:.0f} Min\".format(hours, minutes)\n",
        "    l_time1.append(ot_time)\n",
        "df_final_hr_min.drop(['OT'],axis=1)\n",
        "df_final_hr_min['OT']=l_time1\n",
        "\n",
        "df_HO_final=df_final.copy()\n",
        "df_HO_final=df_HO_final[df_HO_final.Location=='Head Office - Manesar']\n",
        "groupby_ecode_Total_OT = df.groupby(['E.Code'],as_index=False).sum()\n",
        "groupby_ecode_Total_OT_Days = df.groupby(['E.Code'],as_index=False).count()\n",
        "groupby_operation_sum = df_final.groupby(['Operation'],as_index=False).sum()\n",
        "groupby_operation = df_final.groupby(['Operation'],as_index=False).count()\n",
        "groupby_division_sum = df_final.groupby(['Division'],as_index=False).sum()\n",
        "groupby_division = df_final.groupby(['Division'],as_index=False).count()\n",
        "groupby_designation_sum = df_final.groupby(['Designation'],as_index=False).sum()\n",
        "groupby_designation = df_final.groupby(['Designation'],as_index=False).count()\n",
        "groupby_HO_designation_sum = df_HO_final.groupby(['Designation'],as_index=False).sum()\n",
        "groupby_HO_designation = df_HO_final.groupby(['Designation'],as_index=False).count()\n",
        "groupby_location_sum = df_final.groupby(['Location'],as_index=False).sum()\n",
        "groupby_location = df_final.groupby(['Location'],as_index=False).count()\n",
        "groupby_dept_sum = df_final.groupby(['Department','Location'],as_index=False).sum()\n",
        "groupby_dept = df_final.groupby(['Department','Location'],as_index=False).count()\n",
        "print(df_final)\n",
        "print(\"------------------------------\")\n",
        "\n",
        "\n",
        "\n",
        "grp_opr = pd.DataFrame(df_final.groupby(['Operation','E.Code'],as_index=False).size())\n",
        "grp_des = pd.DataFrame(df_final.groupby(['Designation','E.Code'],as_index=False).size())\n",
        "grp_HO_des = pd.DataFrame(df_HO_final.groupby(['Designation','E.Code'],as_index=False).size())\n",
        "grp_div = pd.DataFrame(df_final.groupby(['Division','E.Code'],as_index=False).size())\n",
        "grp_loc = pd.DataFrame(df_final.groupby(['Location','E.Code'],as_index=False).size())\n",
        "grp_dept = pd.DataFrame(df_final.groupby(['Department','E.Code'],as_index=False).size())\n",
        "\n",
        "\n",
        "grp_opr_count=[]\n",
        "for i in range(len(grp_opr)):\n",
        "    grp_opr_count.append(grp_opr.iloc[i]['Operation'])\n",
        "\n",
        "grp_des_count=[]\n",
        "for i in range(len(grp_des)):\n",
        "    grp_des_count.append(grp_des.iloc[i]['Designation'])\n",
        "\n",
        "grp_HO_des_count=[]\n",
        "for i in range(len(grp_HO_des)):\n",
        "    grp_HO_des_count.append(grp_HO_des.iloc[i]['Designation'])\n",
        "\n",
        "grp_div_count=[]\n",
        "for i in range(len(grp_div)):\n",
        "    grp_div_count.append(grp_div.iloc[i]['Division'])\n",
        "\n",
        "grp_loc_count=[]\n",
        "for i in range(len(grp_loc)):\n",
        "    grp_loc_count.append(grp_loc.iloc[i]['Location'])\n",
        "\n",
        "grp_dept_count=[]\n",
        "for i in range(len(grp_dept)):\n",
        "    grp_dept_count.append(grp_dept.iloc[i]['Department'])\n",
        "\n",
        "import collections\n",
        "# initializing dict to store frequency of each element\n",
        "grp_opr_count_array = []\n",
        "grp_opr_count_dict = collections.Counter(grp_opr_count)\n",
        "\n",
        "grp_des_count_array = []\n",
        "grp_des_count_dict = collections.Counter(grp_des_count)\n",
        "\n",
        "grp_HO_des_count_array = []\n",
        "grp_HO_des_count_dict = collections.Counter(grp_HO_des_count)\n",
        "\n",
        "grp_div_count_array = []\n",
        "grp_div_count_dict = collections.Counter(grp_div_count)\n",
        "\n",
        "grp_loc_count_array = []\n",
        "grp_loc_count_dict = collections.Counter(grp_loc_count)\n",
        "\n",
        "grp_dept_count_array = []\n",
        "grp_dept_count_dict = collections.Counter(grp_dept_count)\n",
        "\n",
        "grp_opr_count_array = list(grp_opr_count_dict.values())\n",
        "grp_opr_count_dataframe=pd.DataFrame(grp_opr_count_array,columns=['Number of associates'])\n",
        "\n",
        "grp_des_count_array = list(grp_des_count_dict.values())\n",
        "grp_des_count_dataframe=pd.DataFrame(grp_des_count_array,columns=['Number of associates'])\n",
        "\n",
        "grp_HO_des_count_array = list(grp_HO_des_count_dict.values())\n",
        "grp_HO_des_count_dataframe=pd.DataFrame(grp_HO_des_count_array,columns=['Number of associates'])\n",
        "\n",
        "grp_div_count_array = list(grp_div_count_dict.values())\n",
        "grp_div_count_dataframe=pd.DataFrame(grp_div_count_array,columns=['Number of associates'])\n",
        "\n",
        "grp_loc_count_array = list(grp_loc_count_dict.values())\n",
        "grp_loc_count_dataframe=pd.DataFrame(grp_loc_count_array,columns=['Number of associates'])\n",
        "\n",
        "grp_dept_count_array = list(grp_dept_count_dict.values())\n",
        "grp_dept_count_dataframe=pd.DataFrame(grp_dept_count_array,columns=['Number of associates'])\n",
        "\n",
        "Operation_count = pd.DataFrame(df_final.groupby(['Operation'],as_index=False).size())\n",
        "Division_count = pd.DataFrame(df_final.groupby(['Division'],as_index=False).size())\n",
        "Designation_count = pd.DataFrame(df_final.groupby(['Designation'],as_index=False).size())\n",
        "Location_count = pd.DataFrame(df_final.groupby(['Location'],as_index=False).size())\n",
        "Department_count = pd.DataFrame(df_final.groupby(['Department'],as_index=False).size())\n",
        "\n",
        "#Converting Groupby object into DataFrame to apply CRUD opr.\n",
        "df2=pd.DataFrame(groupby_ecode_Total_OT)\n",
        "df3=pd.DataFrame(groupby_ecode_Total_OT_Days)\n",
        "df4=pd.DataFrame(groupby_operation)\n",
        "df5=pd.DataFrame(groupby_division)\n",
        "df6=pd.DataFrame(groupby_operation_sum)\n",
        "df7=pd.DataFrame(groupby_division_sum)\n",
        "df8=pd.DataFrame(groupby_designation)\n",
        "df9=pd.DataFrame(groupby_designation_sum)\n",
        "df14=pd.DataFrame(groupby_HO_designation)\n",
        "df15=pd.DataFrame(groupby_HO_designation_sum)\n",
        "df10=pd.DataFrame(groupby_location)\n",
        "df11=pd.DataFrame(groupby_location_sum)\n",
        "df12=pd.DataFrame(groupby_dept)\n",
        "df13=pd.DataFrame(groupby_dept_sum)\n",
        "\n",
        "\n",
        "df4=df4.drop(['E.Code','Full Name','Designation','Location','Division','Department','Date'], axis=1)\n",
        "df5=df5.drop(['E.Code','Full Name','Designation','Location','Operation','Department','Date'], axis=1)\n",
        "df8=df8.drop(['E.Code','Full Name','Location','Operation','Division','Department','Date'], axis=1)\n",
        "df14=df14.drop(['E.Code','Full Name','Location','Operation','Division','Department','Date'], axis=1)\n",
        "df10=df10.drop(['E.Code','Full Name','Designation','Operation','Division','Department','Date'], axis=1)\n",
        "df12=df12.drop(['E.Code','Full Name','Designation','Operation','Division','Date'], axis=1)\n",
        "print(df6)\n",
        "df6=df6.drop(['E.Code'], axis=1) \n",
        "df7=df7.drop(['E.Code'], axis=1)\n",
        "df9=df9.drop(['E.Code'], axis=1)\n",
        "df11=df11.drop(['E.Code'], axis=1)\n",
        "df13=df13.drop(['E.Code'], axis=1)\n",
        "\n",
        "df4.rename(columns={'OT': 'Total OT_Days'}, inplace=True)\n",
        "df5.rename(columns={'OT': 'Total OT_Days'}, inplace=True)\n",
        "df8.rename(columns={'OT': 'Total OT_Days'}, inplace=True)\n",
        "df14.rename(columns={'OT': 'Total OT_Days'}, inplace=True)\n",
        "df10.rename(columns={'OT': 'Total OT_Days'}, inplace=True)\n",
        "df12.rename(columns={'OT': 'Total OT_Days'}, inplace=True)\n",
        "# df6.rename(columns={'OT': 'Total OT_Days'}, inplace=True)\n",
        "# df7.rename(columns={'OT': 'Total OT_Days'}, inplace=True)\n",
        "\n",
        "l4=[]\n",
        "for i in df2.index:\n",
        "        frac, whole = math.modf(df2['OT'][i])\n",
        "        mins=int(whole*60+frac*100)\n",
        "        hours=mins//60\n",
        "        minutes=mins%60\n",
        "        if minutes<10:\n",
        "            ot_time = float(\"{}.0{}\".format(hours, minutes))\n",
        "        elif minutes%10==0:\n",
        "            ot_time = float(\"{}.{}0\".format(hours, minutes))\n",
        "        else:\n",
        "            ot_time = float(\"{}.{}\".format(hours, minutes))\n",
        "        l4.append(ot_time)\n",
        "\n",
        "llp=[]\n",
        "llp2=[]\n",
        "for i in df6.index:\n",
        "        frac, whole = math.modf(df6['OT'][i])\n",
        "        mins=int(whole*60+frac*100)\n",
        "        mins2 = int(round(mins/grp_opr_count_dataframe.iloc[i]['Number of associates'],0))\n",
        "\n",
        "        hours=mins//60\n",
        "        minutes=mins%60\n",
        "        if minutes<10:\n",
        "            ot_time = float(\"{}.0{}\".format(hours, minutes))\n",
        "        elif minutes%10==0:\n",
        "            ot_time = float(\"{}.{}0\".format(hours, minutes))\n",
        "        else:\n",
        "            ot_time = float(\"{}.{}\".format(hours, minutes))\n",
        "        llp.append(ot_time)\n",
        "\n",
        "        hours2=mins2//60\n",
        "        minutes2=mins2%60\n",
        "        if minutes2<10:\n",
        "            ot_time2 = float(\"{}.0{}\".format(hours2, minutes2))\n",
        "        elif minutes2%10==0:\n",
        "            ot_time2 = float(\"{}.{}0\".format(hours2, minutes2))\n",
        "        else:\n",
        "            ot_time2 = float(\"{}.{}\".format(hours2, minutes2))\n",
        "        llp2.append(ot_time2)\n",
        "\n",
        "lllp=[]\n",
        "lllp2=[]\n",
        "\n",
        "for i in df7.index:\n",
        "        frac, whole = math.modf(df7['OT'][i])\n",
        "        mins=int(whole*60+frac*100)\n",
        "        mins2 = int(round(mins/grp_div_count_dataframe.iloc[i]['Number of associates'],0))\n",
        "\n",
        "        hours=mins//60\n",
        "        minutes=mins%60\n",
        "        if minutes<10:\n",
        "            ot_time = float(\"{}.0{}\".format(hours, minutes))\n",
        "        elif minutes%10==0:\n",
        "            ot_time = float(\"{}.{}0\".format(hours, minutes))\n",
        "        else:\n",
        "            ot_time = float(\"{}.{}\".format(hours, minutes))\n",
        "        lllp.append(ot_time)\n",
        "\n",
        "        hours2=mins2//60\n",
        "        minutes2=mins2%60\n",
        "        if minutes2<10:\n",
        "            ot_time2 = float(\"{}.0{}\".format(hours2, minutes2))\n",
        "        elif minutes2%10==0:\n",
        "            ot_time2 = float(\"{}.{}0\".format(hours2, minutes2))\n",
        "        else:\n",
        "            ot_time2 = float(\"{}.{}\".format(hours2, minutes2))\n",
        "        lllp2.append(ot_time2)\n",
        "\n",
        "llllp=[]\n",
        "llllp2=[]\n",
        "\n",
        "for i in df9.index:\n",
        "        frac, whole = math.modf(df9['OT'][i])\n",
        "        mins=int(whole*60+frac*100)\n",
        "        mins2 = int(round(mins/grp_des_count_dataframe.iloc[i]['Number of associates'],0))\n",
        "\n",
        "        hours=mins//60\n",
        "        minutes=mins%60\n",
        "        if minutes<10:\n",
        "            ot_time = float(\"{}.0{}\".format(hours, minutes))\n",
        "        elif minutes%10==0:\n",
        "            ot_time = float(\"{}.{}0\".format(hours, minutes))\n",
        "        else:\n",
        "            ot_time = float(\"{}.{}\".format(hours, minutes))\n",
        "        llllp.append(ot_time)\n",
        "\n",
        "        hours2=mins2//60\n",
        "        minutes2=mins2%60\n",
        "        if minutes2<10:\n",
        "            ot_time2 = float(\"{}.0{}\".format(hours2, minutes2))\n",
        "        elif minutes2%10==0:\n",
        "            ot_time2 = float(\"{}.{}0\".format(hours2, minutes2))\n",
        "        else:\n",
        "            ot_time2 = float(\"{}.{}\".format(hours2, minutes2))\n",
        "        llllp2.append(ot_time2)\n",
        "\n",
        "lllllppp=[]\n",
        "lllllppp2=[]\n",
        "\n",
        "for i in df15.index:\n",
        "        frac, whole = math.modf(df15['OT'][i])\n",
        "        mins=int(whole*60+frac*100)\n",
        "        mins2 = int(round(mins/grp_HO_des_count_dataframe.iloc[i]['Number of associates'],0))\n",
        "\n",
        "        hours=mins//60\n",
        "        minutes=mins%60\n",
        "        if minutes<10:\n",
        "            ot_time = float(\"{}.0{}\".format(hours, minutes))\n",
        "        elif minutes%10==0:\n",
        "            ot_time = float(\"{}.{}0\".format(hours, minutes))\n",
        "        else:\n",
        "            ot_time = float(\"{}.{}\".format(hours, minutes))\n",
        "        lllllppp.append(ot_time)\n",
        "\n",
        "        hours2=mins2//60\n",
        "        minutes2=mins2%60\n",
        "        if minutes2<10:\n",
        "            ot_time2 = float(\"{}.0{}\".format(hours2, minutes2))\n",
        "        elif minutes2%10==0:\n",
        "            ot_time2 = float(\"{}.{}0\".format(hours2, minutes2))\n",
        "        else:\n",
        "            ot_time2 = float(\"{}.{}\".format(hours2, minutes2))\n",
        "        lllllppp2.append(ot_time2)\n",
        "\n",
        "lllllp=[]\n",
        "lllllp2=[]\n",
        "\n",
        "for i in df11.index:\n",
        "        frac, whole = math.modf(df11['OT'][i])\n",
        "        mins=int(whole*60+frac*100)\n",
        "        mins2 = int(round(mins/grp_loc_count_dataframe.iloc[i]['Number of associates'],0))\n",
        "\n",
        "        hours=mins//60\n",
        "        minutes=mins%60\n",
        "        if minutes<10:\n",
        "            ot_time = float(\"{}.0{}\".format(hours, minutes))\n",
        "        elif minutes%10==0:\n",
        "            ot_time = float(\"{}.{}0\".format(hours, minutes))\n",
        "        else:\n",
        "            ot_time = float(\"{}.{}\".format(hours, minutes))\n",
        "        lllllp.append(ot_time)\n",
        "\n",
        "        hours2=mins2//60\n",
        "        minutes2=mins2%60\n",
        "        if minutes2<10:\n",
        "            ot_time2 = float(\"{}.0{}\".format(hours2, minutes2))\n",
        "        elif minutes2%10==0:\n",
        "            ot_time2 = float(\"{}.{}0\".format(hours2, minutes2))\n",
        "        else:\n",
        "            ot_time2 = float(\"{}.{}\".format(hours2, minutes2))\n",
        "        lllllp2.append(ot_time2)\n"
      ],
      "metadata": {
        "id": "HxVmZc3nrL5s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9876d66f-c319-4a2a-d7ba-f34cd0e30f01"
      },
      "execution_count": 10,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "l4\n",
            "[]\n",
            "df\n",
            "Empty DataFrame\n",
            "Columns: [E.Code, Date, OT]\n",
            "Index: []\n",
            "Empty DataFrame\n",
            "Columns: [E.Code, Full Name, Designation, Location, Operation, Division, Department, Date, OT]\n",
            "Index: []\n",
            "------------------------------\n",
            "Empty DataFrame\n",
            "Columns: [Operation]\n",
            "Index: []\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-f4a610998743>:545: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
            "  groupby_ecode_Total_OT = df.groupby(['E.Code'],as_index=False).sum()\n",
            "<ipython-input-10-f4a610998743>:547: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
            "  groupby_operation_sum = df_final.groupby(['Operation'],as_index=False).sum()\n",
            "<ipython-input-10-f4a610998743>:549: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
            "  groupby_division_sum = df_final.groupby(['Division'],as_index=False).sum()\n",
            "<ipython-input-10-f4a610998743>:551: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
            "  groupby_designation_sum = df_final.groupby(['Designation'],as_index=False).sum()\n",
            "<ipython-input-10-f4a610998743>:553: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
            "  groupby_HO_designation_sum = df_HO_final.groupby(['Designation'],as_index=False).sum()\n",
            "<ipython-input-10-f4a610998743>:555: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
            "  groupby_location_sum = df_final.groupby(['Location'],as_index=False).sum()\n",
            "<ipython-input-10-f4a610998743>:557: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
            "  groupby_dept_sum = df_final.groupby(['Department','Location'],as_index=False).sum()\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-f4a610998743>\u001b[0m in \u001b[0;36m<cell line: 664>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    662\u001b[0m \u001b[0mdf12\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf12\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'E.Code'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Full Name'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Designation'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Operation'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Division'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m \u001b[0mdf6\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf6\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'E.Code'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m \u001b[0mdf7\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf7\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'E.Code'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[0mdf9\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf9\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'E.Code'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5397\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[0;36m1.0\u001b[0m     \u001b[0;36m0.8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5398\u001b[0m         \"\"\"\n\u001b[0;32m-> 5399\u001b[0;31m         return super().drop(\n\u001b[0m\u001b[1;32m   5400\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5401\u001b[0m             \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4503\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4504\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4505\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4507\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4544\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4545\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4546\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4547\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6932\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6933\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6934\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{list(labels[mask])} not found in axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6935\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6936\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"['E.Code'] not found in axis\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculating and appending Punch time difference for each employee with the corresponding E.Code into dataframe (l)\n",
        "def punchtimeDifference(dataset):\n",
        "  l=[]\n",
        "  for i in range(len(dataset)-1):\n",
        "    j=i+1\n",
        "    x=str(int(dataset.iloc[i]['Time']))\n",
        "    y=str(int(dataset.iloc[j]['Time']))\n",
        "    if len(x)<=5:\n",
        "      x=x.zfill(6)\n",
        "    if len(y)<=5:\n",
        "      y=y.zfill(6)\n",
        "\n",
        "    x = datetime.strptime(x, \"%H%M%S\")\n",
        "    x.strftime(\"%I:%M %p\")\n",
        "    y = datetime.strptime(y, \"%H%M%S\")\n",
        "    y.strftime(\"%I:%M %p\")\n",
        "    l.append([dataset.iloc[i]['E.Code'], dataset.iloc[i]['Date'].date(), dataset.iloc[i]['IN_OUT'], int(dataset.iloc[i]['Time']), datetime.combine(dataset.iloc[j]['Date'], y.time()) - datetime.combine(dataset.iloc[i]['Date'], x.time()),dataset.iloc[i]['Location']])  \n",
        "    i=i+2\n",
        "  return l\n",
        "\n",
        "with ft.ProcessPoolExecutor() as executor:\n",
        "  l=executor.submit(punchtimeDifference,dataset).result()"
      ],
      "metadata": {
        "id": "ipXeikIHSu7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Replacing \":\" with \".\" and getting upto 2 decimal places in Time to make mathematical operations feasible on i\n",
        "for i in range(len(l)):\n",
        "  l[i][4] = l[i][4].__str__().replace(\":\",\".\")\n",
        "  s=l[i][4]\n",
        "  l[i][4]=s[0:-3]\n",
        "\n",
        "for i in range(len(l_shift)):\n",
        "  l_shift[i][0] = l_shift[i][0].__str__().replace(\":\",\".\")\n",
        "  s=l_shift[i][0]\n",
        "  l_shift[i][0]=float(s[0:-3])"
      ],
      "metadata": {
        "id": "tOkbgzhwI3WQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data3= pd.DataFrame(l_shift,columns=['Difference'])\n",
        "dataset3= pd.concat([dataset3,data3],axis=1)"
      ],
      "metadata": {
        "id": "LBJVerAB6Oni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Removing redundant rows and storing in new data-structure\n",
        "l2=[]\n",
        "for i in range(len(l)):\n",
        "  if 'P20' not in str(l[i][2]):\n",
        "    l2.append(l[i]) "
      ],
      "metadata": {
        "id": "ME6usX84dlhy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(l2)):\n",
        "  if 'd' in l2[i][4]:\n",
        "    s=l2[i][4]\n",
        "    s=float(s[7:len(s)])\n",
        "    l2[i][4]=24+s"
      ],
      "metadata": {
        "id": "3msTtAarn0xh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Converting string type to float for Time column\n",
        "for i in range(len(l2)):\n",
        "  try:\n",
        "   l2[i][4]=float(\"{:.2f}\".format(float(l2[i][4])))\n",
        "  except:                      \n",
        "    print(l2[i][0],l2[i][4])\n",
        "\n",
        "for i in range(len(l2)):\n",
        "  try:\n",
        "   l2[i][4]=float(\"{:.2f}\".format(float(l2[i][4])))\n",
        "  except:                      \n",
        "    print(l2[i][0],l2[i][4])"
      ],
      "metadata": {
        "id": "rHo0S3Olewk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Converting time from float to mins, applied logic to check if it is greater than 9hrs & 30mins. Subtacting the \n",
        "result to get over time (minutes) converting and storing it into hrs.minutes format. \"\"\"\n",
        "def punchLocation(l2,dataset3):\n",
        "  l3=[]\n",
        "  for i in range(len(l2)):  \n",
        "    frac, whole = math.modf(l2[i][4])\n",
        "    mins=int(whole*60+frac*100)\n",
        "\n",
        "    try:\n",
        "      #1F A-Shift\n",
        "      if (dataset3.iloc[0]['Start']+1500)>=l2[i][3]>=(dataset3.iloc[0]['Start']-3000) and '1F' in l2[i][5]:\n",
        "        frac1, whole1 = math.modf(dataset3.iloc[0]['Difference'])\n",
        "        mins_dif=int(whole1*60+frac1*100)\n",
        "        mins_dif+=30\n",
        "        if mins>mins_dif:\n",
        "          mins=mins-mins_dif\n",
        "          hours=mins//60\n",
        "          minutes=mins%60\n",
        "          if minutes<10:\n",
        "            ot_time = float(\"{}.0{}\".format(hours, minutes))\n",
        "          elif minutes%10==0:\n",
        "            ot_time = float(\"{}.{}0\".format(hours, minutes))\n",
        "          else:\n",
        "            ot_time = float(\"{}.{}\".format(hours, minutes))\n",
        "          l2[i]=l2[i][:-1]\n",
        "          l2[i].append(ot_time)\n",
        "          l3.append(l2[i])\n",
        "\n",
        "      #1F B-Shift\n",
        "      elif (dataset3.iloc[1]['Start']+1500)>=l2[i][3]>=(dataset3.iloc[1]['Start']-3000) and '1F' in l2[i][5]:\n",
        "        frac1, whole1 = math.modf(dataset3.iloc[1]['Difference'])\n",
        "        mins_dif=int(whole1*60+frac1*100)\n",
        "        mins_dif+=30\n",
        "        if mins>mins_dif:\n",
        "          mins=mins-mins_dif\n",
        "          hours=mins//60\n",
        "          minutes=mins%60\n",
        "          if minutes<10:\n",
        "            ot_time = float(\"{}.0{}\".format(hours, minutes))\n",
        "          elif minutes%10==0:\n",
        "            ot_time = float(\"{}.{}0\".format(hours, minutes))\n",
        "          else:\n",
        "            ot_time = float(\"{}.{}\".format(hours, minutes))\n",
        "          l2[i]=l2[i][:-1]\n",
        "          l2[i].append(ot_time)\n",
        "          l3.append(l2[i])\n",
        "\n",
        "      #1F C-Shift\n",
        "      elif (dataset3.iloc[2]['Start']+1500)>=l2[i][3]>=(dataset3.iloc[2]['Start']-3000) and '1F' in l2[i][5]:\n",
        "        frac1, whole1 = math.modf(dataset3.iloc[2]['Difference'])\n",
        "        mins_dif=int(whole1*60+frac1*100)\n",
        "        mins_dif+=30\n",
        "        if mins>mins_dif:\n",
        "          mins=mins-mins_dif\n",
        "          hours=mins//60\n",
        "          minutes=mins%60\n",
        "          if minutes<10:\n",
        "            ot_time = float(\"{}.0{}\".format(hours, minutes))\n",
        "          elif minutes%10==0:\n",
        "            ot_time = float(\"{}.{}0\".format(hours, minutes))\n",
        "          else:\n",
        "            ot_time = float(\"{}.{}\".format(hours, minutes))\n",
        "          l2[i]=l2[i][:-1]\n",
        "          l2[i].append(ot_time)\n",
        "          l3.append(l2[i])\n",
        "\n",
        "      #HO G-Shift\n",
        "      elif (dataset3.iloc[15]['Start']+10000)>=l2[i][3]>=(dataset3.iloc[15]['Start']-10000) and 'Head' in l2[i][5]:\n",
        "        frac1, whole1 = math.modf(dataset3.iloc[15]['Difference'])\n",
        "        mins_dif=int(whole1*60+frac1*100)\n",
        "        mins_dif+=30\n",
        "        if mins>mins_dif:\n",
        "          mins=mins-mins_dif\n",
        "          hours=mins//60\n",
        "          minutes=mins%60\n",
        "          if minutes<10:\n",
        "            ot_time = float(\"{}.0{}\".format(hours, minutes))\n",
        "          elif minutes%10==0:\n",
        "            ot_time = float(\"{}.{}0\".format(hours, minutes))\n",
        "          else:\n",
        "            ot_time = float(\"{}.{}\".format(hours, minutes))\n",
        "          l2[i]=l2[i][:-1]\n",
        "          l2[i].append(ot_time)\n",
        "          l3.append(l2[i])\n",
        "\n",
        "      #2F A-Shift\n",
        "      elif (dataset3.iloc[3]['Start']+1500)>=l2[i][3]>=(dataset3.iloc[3]['Start']-3000) and '2F' in l2[i][5]:\n",
        "        frac1, whole1 = math.modf(dataset3.iloc[3]['Difference'])\n",
        "        mins_dif=int(whole1*60+frac1*100)\n",
        "        mins_dif+=30\n",
        "        if mins>mins_dif:\n",
        "          mins=mins-mins_dif\n",
        "          hours=mins//60\n",
        "          minutes=mins%60\n",
        "          if minutes<10:\n",
        "            ot_time = float(\"{}.0{}\".format(hours, minutes))\n",
        "          elif minutes%10==0:\n",
        "            ot_time = float(\"{}.{}0\".format(hours, minutes))\n",
        "          else:\n",
        "            ot_time = float(\"{}.{}\".format(hours, minutes))\n",
        "          l2[i]=l2[i][:-1]\n",
        "          l2[i].append(ot_time)\n",
        "          l3.append(l2[i])\n",
        "\n",
        "      #2F B4-Shift\n",
        "      elif (dataset3.iloc[4]['Start']+1500)>=l2[i][3]>=(dataset3.iloc[4]['Start']-3000) and '2F' in l2[i][5]:\n",
        "        frac1, whole1 = math.modf(dataset3.iloc[4]['Difference'])\n",
        "        mins_dif=int(whole1*60+frac1*100)\n",
        "        mins_dif+=30\n",
        "        if mins>mins_dif:\n",
        "          mins=mins-mins_dif\n",
        "          hours=mins//60\n",
        "          minutes=mins%60\n",
        "          if minutes<10:\n",
        "            ot_time = float(\"{}.0{}\".format(hours, minutes))\n",
        "          elif minutes%10==0:\n",
        "            ot_time = float(\"{}.{}0\".format(hours, minutes))\n",
        "          else:\n",
        "            ot_time = float(\"{}.{}\".format(hours, minutes))\n",
        "          l2[i]=l2[i][:-1]\n",
        "          l2[i].append(ot_time)\n",
        "          l3.append(l2[i])\n",
        "\n",
        "      #2F C-Shift\n",
        "      elif (dataset3.iloc[5]['Start']+1500)>=l2[i][3]>=(dataset3.iloc[5]['Start']-3000) and '2F' in l2[i][5]:\n",
        "        frac1, whole1 = math.modf(dataset3.iloc[5]['Difference'])\n",
        "        mins_dif=int(whole1*60+frac1*100)\n",
        "        mins_dif+=30\n",
        "        if mins>mins_dif:\n",
        "          mins=mins-mins_dif\n",
        "          hours=mins//60\n",
        "          minutes=mins%60\n",
        "          if minutes<10:\n",
        "            ot_time = float(\"{}.0{}\".format(hours, minutes))\n",
        "          elif minutes%10==0:\n",
        "            ot_time = float(\"{}.{}0\".format(hours, minutes))\n",
        "          else:\n",
        "            ot_time = float(\"{}.{}\".format(hours, minutes))\n",
        "          l2[i]=l2[i][:-1]\n",
        "          l2[i].append(ot_time)\n",
        "          l3.append(l2[i])\n",
        "\n",
        "      #2F G-Shift\n",
        "      elif (dataset3.iloc[6]['Start']+10000)>=l2[i][3]>=(dataset3.iloc[6]['Start']-10000) and '2F' in l2[i][5]:\n",
        "        frac1, whole1 = math.modf(dataset3.iloc[6]['Difference'])\n",
        "        mins_dif=int(whole1*60+frac1*100)\n",
        "        mins_dif+=30\n",
        "        if mins>mins_dif:\n",
        "          mins=mins-mins_dif\n",
        "          hours=mins//60\n",
        "          minutes=mins%60\n",
        "          if minutes<10:\n",
        "            ot_time = float(\"{}.0{}\".format(hours, minutes))\n",
        "          elif minutes%10==0:\n",
        "            ot_time = float(\"{}.{}0\".format(hours, minutes))\n",
        "          else:\n",
        "            ot_time = float(\"{}.{}\".format(hours, minutes))\n",
        "          l2[i]=l2[i][:-1]\n",
        "          l2[i].append(ot_time)\n",
        "          l3.append(l2[i])\n",
        "\n",
        "      #3F A-Shift\n",
        "      elif (dataset3.iloc[7]['Start']+1500)>=l2[i][3]>=(dataset3.iloc[7]['Start']-3000) and '3F' in l2[i][5]:\n",
        "        frac1, whole1 = math.modf(dataset3.iloc[7]['Difference'])\n",
        "        mins_dif=int(whole1*60+frac1*100)\n",
        "        mins_dif+=30\n",
        "        if mins>mins_dif:\n",
        "          mins=mins-mins_dif\n",
        "          hours=mins//60\n",
        "          minutes=mins%60\n",
        "          if minutes<10:\n",
        "            ot_time = float(\"{}.0{}\".format(hours, minutes))\n",
        "          elif minutes%10==0:\n",
        "            ot_time = float(\"{}.{}0\".format(hours, minutes))\n",
        "          else:\n",
        "            ot_time = float(\"{}.{}\".format(hours, minutes))\n",
        "          l2[i]=l2[i][:-1]\n",
        "          l2[i].append(ot_time)\n",
        "          l3.append(l2[i])\n",
        "\n",
        "      #3F B4-Shift\n",
        "      elif (dataset3.iloc[8]['Start']+1500)>=l2[i][3]>=(dataset3.iloc[8]['Start']-3000) and '3F' in l2[i][5]:\n",
        "        frac1, whole1 = math.modf(dataset3.iloc[8]['Difference'])\n",
        "        mins_dif=int(whole1*60+frac1*100)\n",
        "        mins_dif+=30\n",
        "        if mins>mins_dif:\n",
        "          mins=mins-mins_dif\n",
        "          hours=mins//60\n",
        "          minutes=mins%60\n",
        "          if minutes<10:\n",
        "            ot_time = float(\"{}.0{}\".format(hours, minutes))\n",
        "          elif minutes%10==0:\n",
        "            ot_time = float(\"{}.{}0\".format(hours, minutes))\n",
        "          else:\n",
        "            ot_time = float(\"{}.{}\".format(hours, minutes))\n",
        "          l2[i]=l2[i][:-1]\n",
        "          l2[i].append(ot_time)\n",
        "          l3.append(l2[i])\n",
        "\n",
        "      #3F C-Shift\n",
        "      elif (dataset3.iloc[9]['Start']+1500)>=l2[i][3]>=(dataset3.iloc[9]['Start']-3000) and '3F' in l2[i][5]:\n",
        "        frac1, whole1 = math.modf(dataset3.iloc[9]['Difference'])\n",
        "        mins_dif=int(whole1*60+frac1*100)\n",
        "        mins_dif+=30\n",
        "        if mins>mins_dif:\n",
        "          mins=mins-mins_dif\n",
        "          hours=mins//60\n",
        "          minutes=mins%60\n",
        "          if minutes<10:\n",
        "            ot_time = float(\"{}.0{}\".format(hours, minutes))\n",
        "          elif minutes%10==0:\n",
        "            ot_time = float(\"{}.{}0\".format(hours, minutes))\n",
        "          else:\n",
        "            ot_time = float(\"{}.{}\".format(hours, minutes))\n",
        "          l2[i]=l2[i][:-1]\n",
        "          l2[i].append(ot_time)\n",
        "          l3.append(l2[i])\n",
        "\n",
        "      #3F G-Shift\n",
        "      elif (dataset3.iloc[10]['Start']+10000)>=l2[i][3]>=(dataset3.iloc[10]['Start']-1000) and '3F' in l2[i][5]:\n",
        "        frac1, whole1 = math.modf(dataset3.iloc[10]['Difference'])\n",
        "        mins_dif=int(whole1*60+frac1*100)\n",
        "        mins_dif+=30\n",
        "        if mins>mins_dif:\n",
        "          mins=mins-mins_dif\n",
        "          hours=mins//60\n",
        "          minutes=mins%60\n",
        "          if minutes<10:\n",
        "            ot_time = float(\"{}.0{}\".format(hours, minutes))\n",
        "          elif minutes%10==0:\n",
        "            ot_time = float(\"{}.{}0\".format(hours, minutes))\n",
        "          else:\n",
        "            ot_time = float(\"{}.{}\".format(hours, minutes))\n",
        "          l2[i]=l2[i][:-1]\n",
        "          l2[i].append(ot_time)\n",
        "          l3.append(l2[i])\n",
        "\n",
        "      #4F A-Shift\n",
        "      elif (dataset3.iloc[11]['Start']+1500)>=l2[i][3]>=(dataset3.iloc[11]['Start']-3000) and '4F' in l2[i][5]:\n",
        "        frac1, whole1 = math.modf(dataset3.iloc[11]['Difference'])\n",
        "        mins_dif=int(whole1*60+frac1*100)\n",
        "        mins_dif+=30\n",
        "        if mins>mins_dif:\n",
        "          mins=mins-mins_dif\n",
        "          hours=mins//60\n",
        "          minutes=mins%60\n",
        "          if minutes<10:\n",
        "            ot_time = float(\"{}.0{}\".format(hours, minutes))\n",
        "          elif minutes%10==0:\n",
        "            ot_time = float(\"{}.{}0\".format(hours, minutes))\n",
        "          else:\n",
        "            ot_time = float(\"{}.{}\".format(hours, minutes))\n",
        "          l2[i]=l2[i][:-1]\n",
        "          l2[i].append(ot_time)\n",
        "          l3.append(l2[i])\n",
        "\n",
        "      #4F B-Shift\n",
        "      elif (dataset3.iloc[12]['Start']+1500)>=l2[i][3]>=(dataset3.iloc[12]['Start']-3000) and '4F' in l2[i][5]:\n",
        "        frac1, whole1 = math.modf(dataset3.iloc[12]['Difference'])\n",
        "        mins_dif=int(whole1*60+frac1*100)\n",
        "        mins_dif+=30\n",
        "        if mins>mins_dif:\n",
        "          mins=mins-mins_dif\n",
        "          hours=mins//60\n",
        "          minutes=mins%60\n",
        "          if minutes<10:\n",
        "            ot_time = float(\"{}.0{}\".format(hours, minutes))\n",
        "          elif minutes%10==0:\n",
        "            ot_time = float(\"{}.{}0\".format(hours, minutes))\n",
        "          else:\n",
        "            ot_time = float(\"{}.{}\".format(hours, minutes))\n",
        "          l2[i]=l2[i][:-1]\n",
        "          l2[i].append(ot_time)\n",
        "          l3.append(l2[i])\n",
        "\n",
        "      #4F C-Shift\n",
        "      elif (dataset3.iloc[13]['Start']+1500)>=l2[i][3]>=(dataset3.iloc[13]['Start']-3000) and '4F' in l2[i][5]:\n",
        "        frac1, whole1 = math.modf(dataset3.iloc[13]['Difference'])\n",
        "        mins_dif=int(whole1*60+frac1*100)\n",
        "        mins_dif+=30\n",
        "        if mins>mins_dif:\n",
        "          mins=mins-mins_dif\n",
        "          hours=mins//60\n",
        "          minutes=mins%60\n",
        "          if minutes<10:\n",
        "            ot_time = float(\"{}.0{}\".format(hours, minutes))\n",
        "          elif minutes%10==0:\n",
        "            ot_time = float(\"{}.{}0\".format(hours, minutes))\n",
        "          else:\n",
        "            ot_time = float(\"{}.{}\".format(hours, minutes))\n",
        "          l2[i]=l2[i][:-1]\n",
        "          l2[i].append(ot_time)\n",
        "          l3.append(l2[i])\n",
        "\n",
        "      #4F G-Shift\n",
        "      elif (dataset3.iloc[14]['Start']+10000)>=l2[i][3]>=(dataset3.iloc[14]['Start']-10000) and '4F' in l2[i][5]:\n",
        "        frac1, whole1 = math.modf(dataset3.iloc[14]['Difference'])\n",
        "        mins_dif=int(whole1*60+frac1*100)\n",
        "        mins_dif+=30\n",
        "        if mins>mins_dif:\n",
        "          mins=mins-mins_dif\n",
        "          hours=mins//60\n",
        "          minutes=mins%60\n",
        "          if minutes<10:\n",
        "            ot_time = float(\"{}.0{}\".format(hours, minutes))\n",
        "          elif minutes%10==0:\n",
        "            ot_time = float(\"{}.{}0\".format(hours, minutes))\n",
        "          else:\n",
        "            ot_time = float(\"{}.{}\".format(hours, minutes))\n",
        "          l2[i]=l2[i][:-1]\n",
        "          l2[i].append(ot_time)\n",
        "          l3.append(l2[i])\n",
        "\n",
        "    except:\n",
        "      pass\n",
        "  return l3\n",
        "\n",
        "with ft.ProcessPoolExecutor() as executor:\n",
        "  l3=executor.submit(punchLocation,l2,dataset3).result()"
      ],
      "metadata": {
        "id": "PuIkZ4T9HifE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Removing redundant rows and storing in new data-structure\n",
        "l4=[]\n",
        "for i in range(len(l3)):\n",
        "  if l3[i][5]>0:\n",
        "    l4.append(l3[i]) "
      ],
      "metadata": {
        "id": "YVoWMrFX5ERv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(l4)):\n",
        "  if len(l4[i])==7:\n",
        "    print(l4[i][0],l4[i][1],l4[i][2],l4[i][3],l4[i][4],l4[i][5],l4[i][6])"
      ],
      "metadata": {
        "id": "TVIFMrV9DPKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting 2d list to dataframe to apply CRUD opertations\n",
        "df = pd.DataFrame(l4, columns=['E.Code','Date','IN/OUT','Time','Total Time','OT'])"
      ],
      "metadata": {
        "id": "MMVYG1IjQmbM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_copy=df.copy(deep=True)"
      ],
      "metadata": {
        "id": "lDLevEAY6Boq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Droping an unnecesary column\n",
        "df=df.drop(['IN/OUT','Time','Total Time'], axis=1)"
      ],
      "metadata": {
        "id": "6cSXdPLbbNpX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ll1=[]\n",
        "def binarySearch(arr, l, r, x):\n",
        "\n",
        "\twhile l <= r:\n",
        "\n",
        "\t\tmid = l + (r - l) // 2\n",
        "\n",
        "\t\t# Check if x is present at mid\n",
        "\t\tif arr[mid] == x:\n",
        "\t\t\treturn mid\n",
        "\n",
        "\t\t# If x is greater, ignore left half\n",
        "\t\telif arr[mid] < x:\n",
        "\t\t\tl = mid + 1\n",
        "\n",
        "\t\t# If x is smaller, ignore right half\n",
        "\t\telse:\n",
        "\t\t\tr = mid - 1\n",
        "\n",
        "\t# If we reach here, then the element\n",
        "\t# was not present\n",
        "\treturn -1\n",
        "\n",
        "\n",
        "# Driver Code\n",
        "arr = [int(i) for i in dataset2['E Code']]\n",
        "\n",
        "for i in range(len(df)):\n",
        "  # Function call\n",
        "  result = binarySearch(arr, 0, len(arr)-1, df.iloc[i]['E.Code'])\n",
        "\n",
        "  if result != -1:\n",
        "      ll1.append([dataset2.iloc[result]['Full Name'], dataset2.iloc[result]['Designation'],dataset2.iloc[result]['Location'],dataset2.iloc[result]['Operation'],dataset2.iloc[result]['Division'],dataset2.iloc[result]['Department']])\n",
        "  else:\n",
        "      ll1.append(['NaN','NaN','NaN','NaN','NaN','NaN'])\n"
      ],
      "metadata": {
        "id": "t-N9O3J5cMRa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting 2d list to dataframe to apply CRUD opertations\n",
        "dff = pd.DataFrame(ll1, columns=['Full Name','Designation','Location','Operation','Division','Department'])"
      ],
      "metadata": {
        "id": "hbYSLcPqe7vE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_final = pd.concat([df['E.Code'], dff, df[['Date','OT']]], axis=1)"
      ],
      "metadata": {
        "id": "Qv4sQIm44wv2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#double shift\n",
        "l_double_shift=[]\n",
        "for i in range(len(df_copy)):\n",
        "  if df_copy.iloc[i]['Time']>53000 and df_copy.iloc[i]['Time']<63000:\n",
        "    if df_copy.iloc[i]['Total Time']>=17.50:\n",
        "      l_double_shift.append([df_copy.iloc[i]['E.Code'],df_copy.iloc[i]['Date'],'A-B'])\n",
        "  elif df_copy.iloc[i]['Time']>143000 and df_copy.iloc[i]['Time']<150000:\n",
        "    if df_copy.iloc[i]['Total Time']>=15.50:\n",
        "      l_double_shift.append([df_copy.iloc[i]['E.Code'],df_copy.iloc[i]['Date'],'B-C'])\n",
        "  elif df_copy.iloc[i]['Time']>230000 and df_copy.iloc[i]['Time']<234000:\n",
        "    if df_copy.iloc[i]['Total Time']>=15.50:\n",
        "      l_double_shift.append([df_copy.iloc[i]['E.Code'],df_copy.iloc[i]['Date'],'C-A'])\n",
        "\n",
        "def binarySearch(arr, l, r, x):\n",
        "\twhile l <= r:\n",
        "\n",
        "\t\tmid = l + (r - l) // 2\n",
        "\n",
        "\t\t# Check if x is present at mid\n",
        "\t\tif arr[mid] == x:\n",
        "\t\t\treturn mid\n",
        "\n",
        "\t\t# If x is greater, ignore left half\n",
        "\t\telif arr[mid] < x:\n",
        "\t\t\tl = mid + 1\n",
        "\n",
        "\t\t# If x is smaller, ignore right half\n",
        "\t\telse:\n",
        "\t\t\tr = mid - 1\n",
        "\n",
        "\t# If we reach here, then the element\n",
        "\t# was not present\n",
        "\treturn -1\n",
        "\n",
        "arr = [int(i) for i in dataset2['E Code']]\n",
        "for i in range(len(l_double_shift)):\n",
        "  # Function call\n",
        "  result = binarySearch(arr, 0, len(arr)-1, l_double_shift[i][0])\n",
        "\n",
        "  if result != -1:\n",
        "      l_double_shift[i].append(dataset2.iloc[result]['Full Name'])\n",
        "      l_double_shift[i].append(dataset2.iloc[result]['Designation'])\n",
        "      l_double_shift[i].append(dataset2.iloc[result]['Location'])\n",
        "      l_double_shift[i].append(dataset2.iloc[result]['Operation'])\n",
        "      l_double_shift[i].append(dataset2.iloc[result]['Division'])\n",
        "      l_double_shift[i].append(dataset2.iloc[result]['Department'])\n",
        "  else:\n",
        "      l_double_shift[i].append('NaN')\n",
        "      l_double_shift[i].append('NaN')\n",
        "      l_double_shift[i].append('NaN')\n",
        "      l_double_shift[i].append('NaN')\n",
        "      l_double_shift[i].append('NaN')\n",
        "      l_double_shift[i].append('NaN')"
      ],
      "metadata": {
        "id": "E8n6wVly6ikz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l_double_shift = pd.DataFrame(l_double_shift,columns=['E.Code','Date','Double-Shift','Full Name','Designation','Location','Operation','Division','Department'])"
      ],
      "metadata": {
        "id": "0qh6X0pJ8iaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to add value labels\n",
        "def addlabels(x,y):\n",
        "    for i in range(len(x)):\n",
        "        plt.text(i, y[i], y[i], ha = 'center', bbox = dict(facecolor = 'white', alpha =.8))\n",
        "def addlabels2(x,y):\n",
        "    for i in range(len(x)):\n",
        "        plt.text(i, y[i], y[i], ha = 'center')\n",
        "\n",
        "if len(l_double_shift['Double-Shift'])>1:\n",
        "  l_double_shift_list = list(set(l_double_shift['Double-Shift']))\n",
        "  count_Double_Shift=[]\n",
        "  count_Double_Shift=[list(l_double_shift['Double-Shift']).count(l_double_shift_list[i]) for i in range(len(l_double_shift_list))]\n",
        "  x = l_double_shift_list\n",
        "  plt.figure(figsize=(10, 5)) \n",
        "  plt.bar(x, count_Double_Shift, color = [\"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)]) for i in range(len(l_double_shift['Double-Shift']))])\n",
        "  addlabels(x, count_Double_Shift)\n",
        "  plt.title('Double-Shifts')\n",
        "  plt.xticks(x, rotation ='vertical')\n",
        "  plt.ylabel('count')\n",
        "  plt.subplots_adjust(bottom = 0.15)\n",
        "  plt.savefig('doubleshiftgraph.png',bbox_inches=\"tight\")\n",
        "  \n",
        "\n",
        "if len(l_double_shift['Designation'])>1:\n",
        "  l_double_shift_list = list(set(l_double_shift['Designation']))\n",
        "  count_Double_Shift=[]\n",
        "  count_Double_Shift=[list(l_double_shift['Designation']).count(l_double_shift_list[i]) for i in range(len(l_double_shift_list))]\n",
        "  x = l_double_shift_list\n",
        "  plt.figure(figsize=(10, 5))  \n",
        "  plt.bar(x, count_Double_Shift,color = [\"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)]) for i in range(len(l_double_shift['Designation']))])\n",
        "  addlabels(x, count_Double_Shift)\n",
        "  plt.title('Designations doing Double-Shifts')\n",
        "  plt.xticks(x, rotation ='vertical')\n",
        "  plt.ylabel('count')\n",
        "  plt.subplots_adjust(bottom = 0.15)\n",
        "  plt.savefig('doubleshiftgraph2.png',bbox_inches=\"tight\")\n",
        "\n",
        "\n",
        "if len(l_double_shift['Operation'])>1:\n",
        "  l_double_shift_list = list(set(l_double_shift['Operation']))\n",
        "  count_Double_Shift=[]\n",
        "  count_Double_Shift=[list(l_double_shift['Operation']).count(l_double_shift_list[i]) for i in range(len(l_double_shift_list))]\n",
        "  x = l_double_shift_list\n",
        "  plt.figure(figsize=(10, 5))  \n",
        "  plt.bar(x, count_Double_Shift,color = [\"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)]) for i in range(len(l_double_shift['Operation']))])\n",
        "  addlabels(x, count_Double_Shift)\n",
        "  plt.title('Operations doing Double-Shifts')\n",
        "  plt.xticks(x, rotation ='vertical')\n",
        "  plt.ylabel('count')\n",
        "  plt.subplots_adjust(bottom = 0.15)\n",
        "  plt.savefig('doubleshiftgraph3.png',bbox_inches=\"tight\")\n",
        "\n",
        "\n",
        "if len(l_double_shift['Location'])>1:\n",
        "  l_double_shift_list = list(set(l_double_shift['Location']))\n",
        "  count_Double_Shift=[]\n",
        "  count_Double_Shift=[list(l_double_shift['Location']).count(l_double_shift_list[i]) for i in range(len(l_double_shift_list))]\n",
        "  x = l_double_shift_list\n",
        "  plt.figure(figsize=(10, 5))  \n",
        "  plt.bar(x, count_Double_Shift,color = [\"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)]) for i in range(len(l_double_shift['Location']))])\n",
        "  addlabels(x, count_Double_Shift)\n",
        "  plt.title('Locations doing Double-Shifts')\n",
        "  plt.xticks(x, rotation ='vertical')\n",
        "  plt.ylabel('count')\n",
        "  plt.subplots_adjust(bottom = 0.15)\n",
        "  plt.savefig('doubleshiftgraph4.png',bbox_inches=\"tight\")\n"
      ],
      "metadata": {
        "id": "X8Vs1dezEL_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_hr_min=df_final.copy(deep=True)\n",
        "l_time1=[]\n",
        "for i in df_final_hr_min.index:\n",
        "      minutes, hours = math.modf(df_final_hr_min['OT'][i])\n",
        "      minutes*=100\n",
        "      ot_time = \"{:.0f} Hr {:.0f} Min\".format(hours, minutes)\n",
        "      l_time1.append(ot_time)\n",
        "df_final_hr_min.drop(['OT'],axis=1)\n",
        "df_final_hr_min['OT']=l_time1"
      ],
      "metadata": {
        "id": "ofIvwRvIRBMQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Applying Groupby opr. to group dataframe on basis of E.Code and apply sum and count opr. to \n",
        "compute Total_OT & Total_OT_Days \"\"\"\n",
        "\n",
        "groupby_ecode_Total_OT = df.groupby(['E.Code'],as_index=False).sum()\n",
        "groupby_ecode_Total_OT_Days = df.groupby(['E.Code'],as_index=False).count()\n",
        "groupby_operation_sum = df_final.groupby(['Operation'],as_index=False).sum()\n",
        "groupby_operation = df_final.groupby(['Operation'],as_index=False).count()\n",
        "groupby_division_sum = df_final.groupby(['Division'],as_index=False).sum()\n",
        "groupby_division = df_final.groupby(['Division'],as_index=False).count()\n",
        "groupby_designation_sum = df_final.groupby(['Designation'],as_index=False).sum()\n",
        "groupby_designation = df_final.groupby(['Designation'],as_index=False).count()\n",
        "groupby_location_sum = df_final.groupby(['Location'],as_index=False).sum()\n",
        "groupby_location = df_final.groupby(['Location'],as_index=False).count()\n",
        "groupby_dept_sum = df_final.groupby(['Department'],as_index=False).sum()\n",
        "groupby_dept = df_final.groupby(['Department'],as_index=False).count()"
      ],
      "metadata": {
        "id": "y7apyM_Ssx4E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grp_opr = pd.DataFrame(df_final.groupby(['Operation','E.Code'],as_index=False).size())\n",
        "grp_des = pd.DataFrame(df_final.groupby(['Designation','E.Code'],as_index=False).size())\n",
        "grp_div = pd.DataFrame(df_final.groupby(['Division','E.Code'],as_index=False).size())\n",
        "grp_loc = pd.DataFrame(df_final.groupby(['Location','E.Code'],as_index=False).size())\n",
        "grp_dept = pd.DataFrame(df_final.groupby(['Department','E.Code'],as_index=False).size())"
      ],
      "metadata": {
        "id": "Hjqto3GMDvJE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grp_opr_count=[]\n",
        "for i in range(len(grp_opr)):\n",
        "  grp_opr_count.append(grp_opr.iloc[i]['Operation'])\n",
        "\n",
        "grp_des_count=[]\n",
        "for i in range(len(grp_des)):\n",
        "  grp_des_count.append(grp_des.iloc[i]['Designation'])\n",
        "\n",
        "grp_div_count=[]\n",
        "for i in range(len(grp_div)):\n",
        "  grp_div_count.append(grp_div.iloc[i]['Division'])\n",
        "\n",
        "grp_loc_count=[]\n",
        "for i in range(len(grp_loc)):\n",
        "  grp_loc_count.append(grp_loc.iloc[i]['Location'])\n",
        "  \n",
        "grp_dept_count=[]\n",
        "for i in range(len(grp_dept)):\n",
        "  grp_dept_count.append(grp_dept.iloc[i]['Department'])"
      ],
      "metadata": {
        "id": "KFDXDCQtElZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "# initializing dict to store frequency of each element\n",
        "grp_opr_count_array = []\n",
        "grp_opr_count_dict = collections.Counter(grp_opr_count)\n",
        "\n",
        "grp_des_count_array = []\n",
        "grp_des_count_dict = collections.Counter(grp_des_count)\n",
        "\n",
        "grp_div_count_array = []\n",
        "grp_div_count_dict = collections.Counter(grp_div_count)\n",
        "\n",
        "grp_loc_count_array = []\n",
        "grp_loc_count_dict = collections.Counter(grp_loc_count)\n",
        "\n",
        "grp_dept_count_array = []\n",
        "grp_dept_count_dict = collections.Counter(grp_dept_count)"
      ],
      "metadata": {
        "id": "z1H89n9Cdfcm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grp_opr_count_array = list(grp_opr_count_dict.values())\n",
        "grp_opr_count_dataframe=pd.DataFrame(grp_opr_count_array,columns=['Number of associates'])\n",
        "\n",
        "grp_des_count_array = list(grp_des_count_dict.values())\n",
        "grp_des_count_dataframe=pd.DataFrame(grp_des_count_array,columns=['Number of associates'])\n",
        "\n",
        "grp_div_count_array = list(grp_div_count_dict.values())\n",
        "grp_div_count_dataframe=pd.DataFrame(grp_div_count_array,columns=['Number of associates'])\n",
        "\n",
        "grp_loc_count_array = list(grp_loc_count_dict.values())\n",
        "grp_loc_count_dataframe=pd.DataFrame(grp_loc_count_array,columns=['Number of associates'])\n",
        "\n",
        "grp_dept_count_array = list(grp_dept_count_dict.values())\n",
        "grp_dept_count_dataframe=pd.DataFrame(grp_dept_count_array,columns=['Number of associates'])"
      ],
      "metadata": {
        "id": "VoETfNBxl6tj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Operation_count = pd.DataFrame(df_final.groupby(['Operation'],as_index=False).size())\n",
        "Division_count = pd.DataFrame(df_final.groupby(['Division'],as_index=False).size())\n",
        "Designation_count = pd.DataFrame(df_final.groupby(['Designation'],as_index=False).size())\n",
        "Location_count = pd.DataFrame(df_final.groupby(['Location'],as_index=False).size())\n",
        "Department_count = pd.DataFrame(df_final.groupby(['Department'],as_index=False).size())"
      ],
      "metadata": {
        "id": "1SN9Y1tftIEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Converting Groupby object into DataFrame to apply CRUD opr.\n",
        "df2=pd.DataFrame(groupby_ecode_Total_OT)\n",
        "df3=pd.DataFrame(groupby_ecode_Total_OT_Days)\n",
        "df4=pd.DataFrame(groupby_operation)\n",
        "df5=pd.DataFrame(groupby_division)\n",
        "df6=pd.DataFrame(groupby_operation_sum)\n",
        "df7=pd.DataFrame(groupby_division_sum)\n",
        "df8=pd.DataFrame(groupby_designation)\n",
        "df9=pd.DataFrame(groupby_designation_sum)\n",
        "df10=pd.DataFrame(groupby_location)\n",
        "df11=pd.DataFrame(groupby_location_sum)\n",
        "df12=pd.DataFrame(groupby_dept)\n",
        "df13=pd.DataFrame(groupby_dept_sum)"
      ],
      "metadata": {
        "id": "Lni2QxomtrGa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df4=df4.drop(['E.Code','Full Name','Designation','Location','Division','Department','Date'], axis=1)\n",
        "df5=df5.drop(['E.Code','Full Name','Designation','Location','Operation','Department','Date'], axis=1)\n",
        "df8=df8.drop(['E.Code','Full Name','Location','Operation','Division','Department','Date'], axis=1)\n",
        "df10=df10.drop(['E.Code','Full Name','Designation','Operation','Division','Department','Date'], axis=1)\n",
        "df12=df12.drop(['E.Code','Full Name','Designation','Location','Operation','Division','Date'], axis=1)\n",
        "\n",
        "df6=df6.drop(['E.Code'], axis=1) \n",
        "df7=df7.drop(['E.Code'], axis=1)\n",
        "df9=df9.drop(['E.Code'], axis=1)\n",
        "df11=df11.drop(['E.Code'], axis=1)\n",
        "df13=df13.drop(['E.Code'], axis=1)"
      ],
      "metadata": {
        "id": "QBTNpIROFQgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df4.rename(columns={'OT': 'Total OT_Days'}, inplace=True)\n",
        "df5.rename(columns={'OT': 'Total OT_Days'}, inplace=True)\n",
        "df8.rename(columns={'OT': 'Total OT_Days'}, inplace=True)\n",
        "df10.rename(columns={'OT': 'Total OT_Days'}, inplace=True)\n",
        "df12.rename(columns={'OT': 'Total OT_Days'}, inplace=True)\n",
        "# df6.rename(columns={'OT': 'Total OT_Days'}, inplace=True)\n",
        "# df7.rename(columns={'OT': 'Total OT_Days'}, inplace=True)"
      ],
      "metadata": {
        "id": "yIwq43rcF2jU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l4=[]\n",
        "for i in df2.index:\n",
        "      frac, whole = math.modf(df2['OT'][i])\n",
        "      mins=int(whole*60+frac*100)\n",
        "      hours=mins//60\n",
        "      minutes=mins%60\n",
        "      if minutes<10:\n",
        "          ot_time = float(\"{}.0{}\".format(hours, minutes))\n",
        "      elif minutes%10==0:\n",
        "        ot_time = float(\"{}.{}0\".format(hours, minutes))\n",
        "      else:\n",
        "        ot_time = float(\"{}.{}\".format(hours, minutes))\n",
        "      l4.append(ot_time)"
      ],
      "metadata": {
        "id": "kVlwoaPFRC7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llp=[]\n",
        "llp2=[]\n",
        "for i in df6.index:\n",
        "      frac, whole = math.modf(df6['OT'][i])\n",
        "      mins=int(whole*60+frac*100)\n",
        "      mins2 = int(round(mins/grp_opr_count_dataframe.iloc[i]['Number of associates'],0))\n",
        "\n",
        "      hours=mins//60\n",
        "      minutes=mins%60\n",
        "      if minutes<10:\n",
        "          ot_time = float(\"{}.0{}\".format(hours, minutes))\n",
        "      elif minutes%10==0:\n",
        "        ot_time = float(\"{}.{}0\".format(hours, minutes))\n",
        "      else:\n",
        "        ot_time = float(\"{}.{}\".format(hours, minutes))\n",
        "      llp.append(ot_time)\n",
        "\n",
        "      hours2=mins2//60\n",
        "      minutes2=mins2%60\n",
        "      if minutes2<10:\n",
        "          ot_time2 = float(\"{}.0{}\".format(hours2, minutes2))\n",
        "      elif minutes2%10==0:\n",
        "        ot_time2 = float(\"{}.{}0\".format(hours2, minutes2))\n",
        "      else:\n",
        "        ot_time2 = float(\"{}.{}\".format(hours2, minutes2))\n",
        "      llp2.append(ot_time2)"
      ],
      "metadata": {
        "id": "ShDAJ7cuVPH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lllp=[]\n",
        "lllp2=[]\n",
        "\n",
        "for i in df7.index:\n",
        "      frac, whole = math.modf(df7['OT'][i])\n",
        "      mins=int(whole*60+frac*100)\n",
        "      mins2 = int(round(mins/grp_div_count_dataframe.iloc[i]['Number of associates'],0))\n",
        "\n",
        "      hours=mins//60\n",
        "      minutes=mins%60\n",
        "      if minutes<10:\n",
        "          ot_time = float(\"{}.0{}\".format(hours, minutes))\n",
        "      elif minutes%10==0:\n",
        "        ot_time = float(\"{}.{}0\".format(hours, minutes))\n",
        "      else:\n",
        "        ot_time = float(\"{}.{}\".format(hours, minutes))\n",
        "      lllp.append(ot_time)\n",
        "\n",
        "      hours2=mins2//60\n",
        "      minutes2=mins2%60\n",
        "      if minutes2<10:\n",
        "          ot_time2 = float(\"{}.0{}\".format(hours2, minutes2))\n",
        "      elif minutes2%10==0:\n",
        "        ot_time2 = float(\"{}.{}0\".format(hours2, minutes2))\n",
        "      else:\n",
        "        ot_time2 = float(\"{}.{}\".format(hours2, minutes2))\n",
        "      lllp2.append(ot_time2)"
      ],
      "metadata": {
        "id": "oMiHJS58Y3JC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llllp=[]\n",
        "llllp2=[]\n",
        "\n",
        "for i in df9.index:\n",
        "      frac, whole = math.modf(df9['OT'][i])\n",
        "      mins=int(whole*60+frac*100)\n",
        "      mins2 = int(round(mins/grp_des_count_dataframe.iloc[i]['Number of associates'],0))\n",
        "\n",
        "      hours=mins//60\n",
        "      minutes=mins%60\n",
        "      if minutes<10:\n",
        "          ot_time = float(\"{}.0{}\".format(hours, minutes))\n",
        "      elif minutes%10==0:\n",
        "        ot_time = float(\"{}.{}0\".format(hours, minutes))\n",
        "      else:\n",
        "        ot_time = float(\"{}.{}\".format(hours, minutes))\n",
        "      llllp.append(ot_time)\n",
        "\n",
        "      hours2=mins2//60\n",
        "      minutes2=mins2%60\n",
        "      if minutes2<10:\n",
        "          ot_time2 = float(\"{}.0{}\".format(hours2, minutes2))\n",
        "      elif minutes2%10==0:\n",
        "        ot_time2 = float(\"{}.{}0\".format(hours2, minutes2))\n",
        "      else:\n",
        "        ot_time2 = float(\"{}.{}\".format(hours2, minutes2))\n",
        "      llllp2.append(ot_time2)"
      ],
      "metadata": {
        "id": "KqKDD2dlbpmB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lllllp=[]\n",
        "lllllp2=[]\n",
        "\n",
        "for i in df11.index:\n",
        "      frac, whole = math.modf(df11['OT'][i])\n",
        "      mins=int(whole*60+frac*100)\n",
        "      mins2 = int(round(mins/grp_loc_count_dataframe.iloc[i]['Number of associates'],0))\n",
        "\n",
        "      hours=mins//60\n",
        "      minutes=mins%60\n",
        "      if minutes<10:\n",
        "          ot_time = float(\"{}.0{}\".format(hours, minutes))\n",
        "      elif minutes%10==0:\n",
        "        ot_time = float(\"{}.{}0\".format(hours, minutes))\n",
        "      else:\n",
        "        ot_time = float(\"{}.{}\".format(hours, minutes))\n",
        "      lllllp.append(ot_time)\n",
        "\n",
        "      hours2=mins2//60\n",
        "      minutes2=mins2%60\n",
        "      if minutes2<10:\n",
        "          ot_time2 = float(\"{}.0{}\".format(hours2, minutes2))\n",
        "      elif minutes2%10==0:\n",
        "        ot_time2 = float(\"{}.{}0\".format(hours2, minutes2))\n",
        "      else:\n",
        "        ot_time2 = float(\"{}.{}\".format(hours2, minutes2))\n",
        "      lllllp2.append(ot_time2)"
      ],
      "metadata": {
        "id": "D1w31Appb3SS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llllllp=[]\n",
        "llllllp2=[]\n",
        "\n",
        "for i in df13.index:\n",
        "      frac, whole = math.modf(df13['OT'][i])\n",
        "      mins=int(whole*60+frac*100)\n",
        "      mins2 = int(round(mins/grp_dept_count_dataframe.iloc[i]['Number of associates'],0))\n",
        "\n",
        "      hours=mins//60\n",
        "      minutes=mins%60\n",
        "      if minutes<10:\n",
        "          ot_time = float(\"{}.0{}\".format(hours, minutes))\n",
        "      elif minutes%10==0:\n",
        "        ot_time = float(\"{}.{}0\".format(hours, minutes))\n",
        "      else:\n",
        "        ot_time = float(\"{}.{}\".format(hours, minutes))\n",
        "      llllllp.append(ot_time)\n",
        "\n",
        "      hours2=mins2//60\n",
        "      minutes2=mins2%60\n",
        "      if minutes2<10:\n",
        "          ot_time2 = float(\"{}.0{}\".format(hours2, minutes2))\n",
        "      elif minutes2%10==0:\n",
        "        ot_time2 = float(\"{}.{}0\".format(hours2, minutes2))\n",
        "      else:\n",
        "        ot_time2 = float(\"{}.{}\".format(hours2, minutes2))\n",
        "      llllllp2.append(ot_time2)"
      ],
      "metadata": {
        "id": "KOZKaV3csGRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2['Total OT']=l4\n",
        "df6['Total OT']=llp\n",
        "df6['Average OT']=llp2\n",
        "df7['Total OT']=lllp\n",
        "df7['Average OT']=lllp2\n",
        "\n",
        "df9['Total OT']=llllp\n",
        "df9['Average OT']=llllp2\n",
        "\n",
        "df11['Total OT']=lllllp\n",
        "df11['Average OT']=lllllp2\n",
        "\n",
        "df13['Total OT']=llllllp\n",
        "df13['Average OT']=llllllp2"
      ],
      "metadata": {
        "id": "80ucpX7yBYHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Droping an unnecesary column\n",
        "df3=df3.drop(['Date'], axis=1)"
      ],
      "metadata": {
        "id": "UkZguCTLTkmw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2=df2.drop(['OT'], axis=1)\n",
        "df6=df6.drop(['OT'], axis=1)\n",
        "df7=df7.drop(['OT'], axis=1)\n",
        "df9=df9.drop(['OT'], axis=1)\n",
        "df11=df11.drop(['OT'], axis=1)\n",
        "df13=df13.drop(['OT'], axis=1)"
      ],
      "metadata": {
        "id": "gvCcBpNUBYLm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Renaming Columns\n",
        "#df2.rename(columns={'OT': 'Total OT'}, inplace=True)\n",
        "df3.rename(columns={'OT': 'Total OT_Days'}, inplace=True)"
      ],
      "metadata": {
        "id": "Rv6uJ4qzwvG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating a final dataframe (E.Code, Total OT_Days, Total OT)\n",
        "# result = pd.concat([df3,df2], axis=1)\n",
        "result_2 =  pd.concat([df4[['Operation','Total OT_Days']],df6['Total OT'],grp_opr_count_dataframe['Number of associates'],df6['Average OT']], axis=1)\n",
        "result_3 =  pd.concat([df5,df7['Total OT'],grp_div_count_dataframe['Number of associates'],df7['Average OT']], axis=1)\n",
        "result_4 =  pd.concat([df8,df9['Total OT'],grp_des_count_dataframe['Number of associates'],df9['Average OT']], axis=1)\n",
        "result_5 =  pd.concat([df10,df11['Total OT'],grp_loc_count_dataframe['Number of associates'],df11['Average OT']], axis=1)\n",
        "result_6 =  pd.concat([df12,df13['Total OT'],grp_dept_count_dataframe['Number of associates'],df13['Average OT']], axis=1)"
      ],
      "metadata": {
        "id": "seE1Q1RzvHf6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_2.rename(columns={'size': 'Count'}, inplace=True)\n",
        "result_3.rename(columns={'size': 'Count'}, inplace=True)\n",
        "result_4.rename(columns={'size': 'Count'}, inplace=True)\n",
        "result_5.rename(columns={'size': 'Count'}, inplace=True)\n",
        "result_6.rename(columns={'size': 'Count'}, inplace=True)"
      ],
      "metadata": {
        "id": "VXMk2cuoK7bG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ll2=[]\n",
        "def binarySearch(arr, l, r, x):\n",
        "\n",
        "\twhile l <= r:\n",
        "\n",
        "\t\tmid = l + (r - l) // 2\n",
        "\n",
        "\t\t# Check if x is present at mid\n",
        "\t\tif arr[mid] == x:\n",
        "\t\t\treturn mid\n",
        "\n",
        "\t\t# If x is greater, ignore left half\n",
        "\t\telif arr[mid] < x:\n",
        "\t\t\tl = mid + 1\n",
        "\n",
        "\t\t# If x is smaller, ignore right half\n",
        "\t\telse:\n",
        "\t\t\tr = mid - 1\n",
        "\n",
        "\t# If we reach here, then the element\n",
        "\t# was not present\n",
        "\treturn -1\n",
        "\n",
        "\n",
        "# Driver Code\n",
        "arr = [int(i) for i in dataset2['E Code']]\n",
        "\n",
        "for i in range(len(df3)):\n",
        "  # Function call\n",
        "  res = binarySearch(arr, 0, len(arr)-1, df3.iloc[i]['E.Code'])\n",
        "\n",
        "  if res != -1:\n",
        "      ll2.append([dataset2.iloc[res]['Full Name'], dataset2.iloc[res]['Designation'],dataset2.iloc[res]['Operation'],dataset2.iloc[res]['Division'],dataset2.iloc[res]['Department']])\n",
        "  else:\n",
        "      ll2.append(['NaN','NaN','NaN','NaN','NaN'])\n"
      ],
      "metadata": {
        "id": "F4mBk9Xo7-ix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting 2d list to dataframe to apply CRUD opertations\n",
        "dfff = pd.DataFrame(ll2, columns=['Full Name','Designation','Operation','Division','Department'])"
      ],
      "metadata": {
        "id": "EaPJEoHG84RJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = pd.concat([df3['E.Code'], dfff, df3['Total OT_Days'], df2['Total OT']], axis=1)"
      ],
      "metadata": {
        "id": "rLcWdyDc84RK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_hr_min=result.copy(deep=True)\n",
        "l_time2=[]\n",
        "for i in result_hr_min.index:\n",
        "      minutes, hours = math.modf(result_hr_min['Total OT'][i])\n",
        "      minutes*=100\n",
        "      ot_time = \"{:.0f} Hr {:.0f} Min\".format(hours, minutes)\n",
        "      l_time2.append(ot_time)\n",
        "result_hr_min.drop(['Total OT'],axis=1)\n",
        "result_hr_min['Total OT']=l_time2"
      ],
      "metadata": {
        "id": "SaDcuLZNXFj8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l_diff=[]\n",
        "if date_diff==88 or 89 or 90 or 91 or 92:\n",
        "  for i in range(len(result)):\n",
        "    if result.iloc[i]['Total OT']>50:\n",
        "      l_diff.append([result.iloc[i]['E.Code'],result.iloc[i]['Full Name'],result.iloc[i]['Designation'],result.iloc[i]['Operation'],result.iloc[i]['Division'],result.iloc[i]['Department'],result.iloc[i]['Total OT_Days'],result.iloc[i]['Total OT']])\n",
        "elif date_diff==28 or 29 or 30 or 31:\n",
        "  for i in range(len(result)):\n",
        "    if result.iloc[i]['Total OT']>16:\n",
        "      l_diff.append([result.iloc[i]['E.Code'],result.iloc[i]['Full Name'],result.iloc[i]['Designation'],result.iloc[i]['Operation'],result.iloc[i]['Division'],result.iloc[i]['Department'],result.iloc[i]['Total OT_Days'],result.iloc[i]['Total OT']])\n",
        "else:\n",
        "  for i in range(len(result)):\n",
        "    if result.iloc[i]['Total OT']>((16/30)*date_diff):\n",
        "      l_diff.append([result.iloc[i]['E.Code'],result.iloc[i]['Full Name'],result.iloc[i]['Designation'],result.iloc[i]['Operation'],result.iloc[i]['Division'],result.iloc[i]['Department'],result.iloc[i]['Total OT_Days'],result.iloc[i]['Total OT']])\n"
      ],
      "metadata": {
        "id": "1CEYy-v5zggZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l_diff = pd.DataFrame(l_diff, columns=['E.Code','Full Name','Designation','Operation','Division','Department','Total OT_Days','Total OT'])"
      ],
      "metadata": {
        "id": "IsP--vL41-Eu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l_diff_hr_min=l_diff.copy(deep=True)\n",
        "l_time3=[]\n",
        "for i in l_diff_hr_min.index:\n",
        "      minutes, hours = math.modf(l_diff_hr_min['Total OT'][i])\n",
        "      minutes*=100\n",
        "      ot_time = \"{:.0f} Hr {:.0f} Min\".format(hours, minutes)\n",
        "      l_time3.append(ot_time)\n",
        "l_diff_hr_min.drop(['Total OT'],axis=1)\n",
        "l_diff_hr_min['Total OT']=l_time3"
      ],
      "metadata": {
        "id": "pubvL0fw7neN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if len(l_diff_hr_min['Designation'])>1:\n",
        "  l_diff_hr_min_list = list(set(l_diff_hr_min['Designation']))\n",
        "  count_designation=[]\n",
        "  count_designation=[list(l_diff_hr_min['Designation']).count(l_diff_hr_min_list[i]) for i in range(len(l_diff_hr_min_list))]\n",
        "  x = l_diff_hr_min_list\n",
        "  plt.figure(figsize=(10, 8))  \n",
        "  plt.bar(x, count_designation,color = [\"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)]) for i in range(len(l_diff_hr_min['Designation']))])\n",
        "  addlabels(x, count_designation)\n",
        "  plt.title('Desgnations exceeding OT Limit')\n",
        "  plt.xticks(x, rotation ='vertical')\n",
        "  plt.ylabel('count')\n",
        "  plt.subplots_adjust(bottom = 0.15)\n",
        "  plt.savefig('otlimit.png',bbox_inches=\"tight\")\n",
        "\n",
        "\n",
        "if len(l_diff_hr_min['Operation'])>1:\n",
        "  l_diff_hr_min_list = list(set(l_diff_hr_min['Operation']))\n",
        "  count_designation=[]\n",
        "  count_designation=[list(l_diff_hr_min['Operation']).count(l_diff_hr_min_list[i]) for i in range(len(l_diff_hr_min_list))]\n",
        "  x = l_diff_hr_min_list\n",
        "  plt.figure(figsize=(10, 8))  \n",
        "  plt.bar(x, count_designation,color = [\"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)]) for i in range(len(l_double_shift['Operation']))])\n",
        "  addlabels(x, count_designation)\n",
        "  plt.title('Operations exceeding OT Limit')\n",
        "  plt.xticks(x, rotation ='vertical')\n",
        "  plt.ylabel('count')\n",
        "  plt.subplots_adjust(bottom = 0.15)\n",
        "  plt.savefig('otlimit2.png',bbox_inches=\"tight\")\n"
      ],
      "metadata": {
        "id": "1O1YGtKPPOUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sorting dataframe in descending order on basis of Total OT_Days (User can get top x employees on basis of Total OT_Days)\n",
        "cont2=result.sort_values(by=['Total OT_Days'], ascending=False)"
      ],
      "metadata": {
        "id": "RosYOBSMvgbb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cont2_hr_min=cont2.copy(deep=True)\n",
        "l_time4=[]\n",
        "for i in cont2_hr_min.index:\n",
        "      minutes, hours = math.modf(cont2_hr_min['Total OT'][i])\n",
        "      minutes*=100\n",
        "      ot_time = \"{:.0f} Hr {:.0f} Min\".format(hours, minutes)\n",
        "      l_time4.append(ot_time)\n",
        "cont2_hr_min.drop(['Total OT'],axis=1)\n",
        "cont2_hr_min['Total OT']=l_time4"
      ],
      "metadata": {
        "id": "_-IaNADAYmlG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cont2_consecutive=[]\n",
        "i=0\n",
        "while cont2.iloc[i]['Total OT_Days']>=10:\n",
        "  cont2_consecutive.append(cont2.iloc[i]['E.Code'])\n",
        "  i+=1"
      ],
      "metadata": {
        "id": "0amKkxv4ng4S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def consecutivecalc():\n",
        "  l_con=[]\n",
        "  for x in cont2_consecutive:\n",
        "    for j in range(len(df_final)):\n",
        "      if x == df_final.iloc[j]['E.Code']:\n",
        "        l_con.append([x, df_final.iloc[j]['Date']])\n",
        "  return l_con\n",
        "\n",
        "with ft.ProcessPoolExecutor() as executor:\n",
        "  l_con=executor.submit(consecutivecalc).result()"
      ],
      "metadata": {
        "id": "ZSqRP1R9otBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l_10con=[]\n",
        "for j in cont2_consecutive:\n",
        "  p,c=0,1\n",
        "  for i in range(len(l_con)):\n",
        "    p=i+1\n",
        "    if p <= len(l_con)-1:\n",
        "      if j==l_con[i][0] and j==l_con[p][0]:\n",
        "          if l_con[i][1].day-l_con[p][1].day==-1:\n",
        "            c+=1\n",
        "          elif l_con[i][1].weekday()==4:\n",
        "            if l_con[i][1].day-l_con[p][1].day==-3:\n",
        "              c+=1\n",
        "  if c>=10:\n",
        "    l_10con.append(j)"
      ],
      "metadata": {
        "id": "XkWmq_OPq7I6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l_10_final=[]\n",
        "j=0\n",
        "while j<len(l_10con):\n",
        "  for i in range(len(result)):\n",
        "    if result.iloc[i]['E.Code']== l_10con[j]:\n",
        "      l_10_final.append([result.iloc[i]['E.Code'],result.iloc[i]['Full Name'],result.iloc[i]['Designation'],result.iloc[i]['Operation'],result.iloc[i]['Division'],result.iloc[i]['Department']])\n",
        "      break;\n",
        "  j+=1\n",
        "\n",
        "dfff_10 = pd.DataFrame(l_10_final, columns=['E.Code','Full Name','Designation','Operation','Division','Department'])\n"
      ],
      "metadata": {
        "id": "4IHS-p3mzG_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if len(dfff_10['Designation'])>1:\n",
        "  dfff_10_list = list(set(dfff_10['Designation']))\n",
        "  count_designation=[]\n",
        "  count_designation=[list(dfff_10['Designation']).count(dfff_10_list[i]) for i in range(len(dfff_10_list))]\n",
        "  x = dfff_10_list\n",
        "  plt.figure(figsize=(10, 8))  \n",
        "  plt.bar(x, count_designation,color = [\"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)]) for i in range(len(dfff_10['Designation']))])\n",
        "  addlabels(x, count_designation)\n",
        "  plt.title('Desgnations exceeding 10 consecutive day OT limit')\n",
        "  plt.xticks(x, rotation ='vertical')\n",
        "  plt.ylabel('count')\n",
        "  plt.subplots_adjust(bottom = 0.15)\n",
        "  plt.savefig('cons.png',bbox_inches=\"tight\")\n",
        "\n",
        "\n",
        "if len(dfff_10['Division'])>1:\n",
        "  dfff_10_list = list(set(dfff_10['Division']))\n",
        "  count_div=[]\n",
        "  count_div=[list(dfff_10['Division']).count(dfff_10_list[i]) for i in range(len(dfff_10_list))]\n",
        "  x = dfff_10_list\n",
        "  plt.figure(figsize=(10, 8))  \n",
        "  plt.bar(x, count_div,color = [\"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)]) for i in range(len(dfff_10['Division']))])\n",
        "  addlabels(x, count_div)\n",
        "  plt.title('Divisions exceeding 10 consecutive day OT limit')\n",
        "  plt.xticks(x, rotation ='vertical')\n",
        "  plt.ylabel('count')\n",
        "  plt.subplots_adjust(bottom = 0.15)\n",
        "  plt.savefig('cons2.png',bbox_inches=\"tight\")\n",
        "\n",
        "if len(dfff_10['Operation'])>1:\n",
        "  dfff_10_list = list(set(dfff_10['Operation']))\n",
        "  count_operation=[]\n",
        "  count_operation=[list(dfff_10['Operation']).count(dfff_10_list[i]) for i in range(len(dfff_10_list))]\n",
        "  x = dfff_10_list\n",
        "  plt.figure(figsize=(10, 8))  \n",
        "  plt.bar(x, count_operation,color = [\"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)]) for i in range(len(dfff_10['Operation']))])\n",
        "  addlabels(x, count_operation)\n",
        "  plt.title('Operations exceeding 10 consecutive day OT limit')\n",
        "  plt.xticks(x, rotation ='vertical')\n",
        "  plt.ylabel('count')\n",
        "  plt.subplots_adjust(bottom = 0.15)\n",
        "  plt.savefig('cons3.png',bbox_inches=\"tight\")\n"
      ],
      "metadata": {
        "id": "wTKxSP6Qa5D1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sorting dataframe in descending order on basis of Total OT (User can get top x employees on basis of Total OT)\n",
        "cont3=result.sort_values(by=['Total OT'], ascending=False)"
      ],
      "metadata": {
        "id": "ssR8YdwbPZnz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cont3_hr_min=cont3.copy(deep=True)\n",
        "l_time5=[]\n",
        "for i in cont3_hr_min.index:\n",
        "      minutes, hours = math.modf(cont3_hr_min['Total OT'][i])\n",
        "      minutes*=100\n",
        "      ot_time = \"{:.0f} Hr {:.0f} Min\".format(hours, minutes)\n",
        "      l_time5.append(ot_time)\n",
        "cont3_hr_min.drop(['Total OT'],axis=1)\n",
        "cont3_hr_min['Total OT']=l_time5"
      ],
      "metadata": {
        "id": "upWH6ibrY5QD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cont4=result_2.sort_values(by=['Total OT_Days'], ascending=False)"
      ],
      "metadata": {
        "id": "_QCkyOLlDLPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cont4_hr_min=cont4.copy(deep=True)\n",
        "l_time6=[]\n",
        "l_time6n=[]\n",
        "for i in cont4_hr_min.index:\n",
        "      minutes, hours = math.modf(cont4_hr_min['Total OT'][i])\n",
        "      minutesn, hoursn = math.modf(cont4_hr_min['Average OT'][i])\n",
        "      minutes*=100\n",
        "      ot_time = \"{:.0f} Hr {:.0f} Min\".format(hours, minutes)\n",
        "      l_time6.append(ot_time)\n",
        "      minutesn*=100\n",
        "      ot_timen = \"{:.0f} Hr {:.0f} Min\".format(hoursn, minutesn)\n",
        "      l_time6n.append(ot_timen)\n",
        "cont4_hr_min.drop(['Total OT'],axis=1)\n",
        "cont4_hr_min['Total OT']=l_time6\n",
        "cont4_hr_min.drop(['Average OT'],axis=1)\n",
        "cont4_hr_min['Average OT']=l_time6n"
      ],
      "metadata": {
        "id": "Ipuxya7zZDLB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cont5=result_2.sort_values(by=['Total OT'], ascending=False)"
      ],
      "metadata": {
        "id": "E_hyzAg1cYvd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cont5_hr_min=cont5.copy(deep=True)\n",
        "l_time7=[]\n",
        "l_time7n=[]\n",
        "for i in cont5_hr_min.index:\n",
        "      minutes, hours = math.modf(cont5_hr_min['Total OT'][i])\n",
        "      minutes*=100\n",
        "      ot_time = \"{:.0f} Hr {:.0f} Min\".format(hours, minutes)\n",
        "      l_time7.append(ot_time)\n",
        "      minutesn, hoursn = math.modf(cont5_hr_min['Average OT'][i])\n",
        "      minutesn*=100\n",
        "      ot_timen = \"{:.0f} Hr {:.0f} Min\".format(hoursn, minutesn)\n",
        "      l_time7n.append(ot_timen)\n",
        "cont5_hr_min.drop(['Total OT'],axis=1)\n",
        "cont5_hr_min['Total OT']=l_time7\n",
        "cont5_hr_min.drop(['Average OT'],axis=1)\n",
        "cont5_hr_min['Average OT']=l_time7n"
      ],
      "metadata": {
        "id": "zI7TtjDoZMvn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if len(cont4_hr_min['Operation'])>1:\n",
        "  cont4_hr_min_list = list(cont4_hr_min['Operation'])\n",
        "  cont4_hr_min_list2 = list(cont4_hr_min['Total OT_Days'])\n",
        "  plt.figure(figsize=(10, 8))  \n",
        "  plt.bar(cont4_hr_min_list, cont4_hr_min_list2,color = [\"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)]) for i in range(len(cont4_hr_min['Operation']))])\n",
        "  addlabels(cont4_hr_min_list, cont4_hr_min_list2)\n",
        "  plt.title('Operations wise total OT days')\n",
        "  plt.xticks(cont4_hr_min_list, rotation ='vertical')\n",
        "  plt.ylabel('Total OT Days')\n",
        "  plt.subplots_adjust(bottom = 0.15)\n",
        "  plt.savefig('opr.png',bbox_inches=\"tight\")\n",
        "\n",
        "\n",
        "if len(cont5_hr_min['Operation'])>1:\n",
        "  cont5_hr_min_list = list(cont5_hr_min['Operation'])\n",
        "  cont5_hr_min_list2 = list(cont5_hr_min['Total OT'])\n",
        "  plt.figure(figsize=(10, 8))  \n",
        "  plt.bar(cont5_hr_min_list[::-1], cont5_hr_min_list2[::-1],color = [\"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)]) for i in range(len(cont5_hr_min['Operation']))])\n",
        "  addlabels(cont5_hr_min_list[::-1], cont5_hr_min_list2[::-1])\n",
        "  plt.title('Operations wise total OT')\n",
        "  plt.xticks(cont5_hr_min_list, rotation ='vertical')\n",
        "  plt.ylabel('Total OT')\n",
        "  plt.subplots_adjust(bottom = 0.15)\n",
        "  plt.savefig('opr2.png',bbox_inches=\"tight\")\n"
      ],
      "metadata": {
        "id": "lXa1KuEriX_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cont6=result_3.sort_values(by=['Total OT_Days'], ascending=False)"
      ],
      "metadata": {
        "id": "BTusvXDhcbbW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cont6_hr_min=cont6.copy(deep=True)\n",
        "l_time8=[]\n",
        "l_time8n=[]\n",
        "for i in cont6_hr_min.index:\n",
        "      minutes, hours = math.modf(cont6_hr_min['Total OT'][i])\n",
        "      minutes*=100\n",
        "      ot_time = \"{:.0f} Hr {:.0f} Min\".format(hours, minutes)\n",
        "      l_time8.append(ot_time)\n",
        "\n",
        "      minutesn, hoursn = math.modf(cont6_hr_min['Average OT'][i])\n",
        "      minutesn*=100\n",
        "      ot_timen = \"{:.0f} Hr {:.0f} Min\".format(hoursn, minutesn)\n",
        "      l_time8n.append(ot_timen)\n",
        "cont6_hr_min.drop(['Total OT'],axis=1)\n",
        "cont6_hr_min['Total OT']=l_time8\n",
        "\n",
        "cont6_hr_min.drop(['Average OT'],axis=1)\n",
        "cont6_hr_min['Average OT']=l_time8n"
      ],
      "metadata": {
        "id": "pX_Gaj_7ZWu_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cont7=result_3.sort_values(by=['Total OT'], ascending=False)"
      ],
      "metadata": {
        "id": "pvbHsTI3cbeu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cont7_hr_min=cont7.copy(deep=True)\n",
        "l_time9=[]\n",
        "l_time9n=[]\n",
        "\n",
        "for i in cont7_hr_min.index:\n",
        "      minutes, hours = math.modf(cont7_hr_min['Total OT'][i])\n",
        "      minutes*=100\n",
        "      ot_time = \"{:.0f} Hr {:.0f} Min\".format(hours, minutes)\n",
        "      l_time9.append(ot_time)\n",
        "\n",
        "      minutesn, hoursn = math.modf(cont7_hr_min['Average OT'][i])\n",
        "      minutesn*=100\n",
        "      ot_timen = \"{:.0f} Hr {:.0f} Min\".format(hoursn, minutesn)\n",
        "      l_time9n.append(ot_timen)\n",
        "cont7_hr_min.drop(['Total OT'],axis=1)\n",
        "cont7_hr_min['Total OT']=l_time9\n",
        "\n",
        "cont7_hr_min.drop(['Average OT'],axis=1)\n",
        "cont7_hr_min['Average OT']=l_time9n"
      ],
      "metadata": {
        "id": "OEjW8o_PZhIr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if len(cont6_hr_min['Division'])>1:\n",
        "  cont6_hr_min_list = list(cont6_hr_min['Division'])\n",
        "  cont6_hr_min_list2 = list(cont6_hr_min['Total OT_Days'])\n",
        "  plt.figure(figsize=(20, 10))  \n",
        "  plt.bar(cont6_hr_min_list, cont6_hr_min_list2,align='edge', width=0.3,color = [\"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)]) for i in range(len(cont6_hr_min['Division']))])\n",
        "  addlabels2(cont6_hr_min_list, cont6_hr_min_list2)\n",
        "  plt.title('Division wise total OT days')\n",
        "  plt.xticks(cont6_hr_min_list, rotation ='vertical')\n",
        "  plt.ylabel('Total OT Days')\n",
        "  plt.subplots_adjust(bottom = 0.15)\n",
        "  plt.savefig('div.png',bbox_inches=\"tight\")\n",
        "\n",
        "\n",
        "if len(cont7_hr_min['Division'])>1:\n",
        "  cont7_hr_min_list = list(cont7_hr_min['Division'])\n",
        "  cont7_hr_min_list2 = list(cont7_hr_min['Total OT'])\n",
        "  plt.figure(figsize=(15, 15))  \n",
        "  plt.bar(cont7_hr_min_list[::-1], cont7_hr_min_list2[::-1],color = [\"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)]) for i in range(len(cont7_hr_min['Division']))])\n",
        "  addlabels2(cont7_hr_min_list[::-1], cont7_hr_min_list2[::-1])\n",
        "  plt.title('Division wise total OT')\n",
        "  plt.xticks(cont7_hr_min_list, rotation ='vertical')\n",
        "  plt.ylabel('Total OT')\n",
        "  plt.subplots_adjust(bottom = 0.15)\n",
        "  plt.savefig('div2.png',bbox_inches=\"tight\")\n"
      ],
      "metadata": {
        "id": "H10aEqak9QoQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cont8=result_4.sort_values(by=['Total OT_Days'], ascending=False)"
      ],
      "metadata": {
        "id": "REvf2O9ccppO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cont8_hr_min=cont8.copy(deep=True)\n",
        "l_time10=[]\n",
        "l_time10n=[]\n",
        "\n",
        "for i in cont8_hr_min.index:\n",
        "      minutes, hours = math.modf(cont8_hr_min['Total OT'][i])\n",
        "      minutes*=100\n",
        "      ot_time = \"{:.0f} Hr {:.0f} Min\".format(hours, minutes)\n",
        "      l_time10.append(ot_time)\n",
        "\n",
        "      minutesn, hoursn = math.modf(cont8_hr_min['Average OT'][i])\n",
        "      minutesn*=100\n",
        "      ot_timen = \"{:.0f} Hr {:.0f} Min\".format(hoursn, minutesn)\n",
        "      l_time10n.append(ot_timen)\n",
        "cont8_hr_min.drop(['Total OT'],axis=1)\n",
        "cont8_hr_min['Total OT']=l_time10\n",
        "\n",
        "cont8_hr_min.drop(['Average OT'],axis=1)\n",
        "cont8_hr_min['Average OT']=l_time10n"
      ],
      "metadata": {
        "id": "YxftEMO4Ztw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cont9=result_4.sort_values(by=['Total OT'], ascending=False)"
      ],
      "metadata": {
        "id": "YBrX17IbcppO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cont9_hr_min=cont9.copy(deep=True)\n",
        "l_time11=[]\n",
        "l_time11n=[]\n",
        "\n",
        "for i in cont9_hr_min.index:\n",
        "      minutes, hours = math.modf(cont9_hr_min['Total OT'][i])\n",
        "      minutes*=100\n",
        "      ot_time = \"{:.0f} Hr {:.0f} Min\".format(hours, minutes)\n",
        "      l_time11.append(ot_time)\n",
        "\n",
        "      minutesn, hoursn = math.modf(cont9_hr_min['Average OT'][i])\n",
        "      minutesn*=100\n",
        "      ot_timen = \"{:.0f} Hr {:.0f} Min\".format(hoursn, minutesn)\n",
        "      l_time11n.append(ot_timen)\n",
        "cont9_hr_min.drop(['Total OT'],axis=1)\n",
        "cont9_hr_min['Total OT']=l_time11\n",
        "\n",
        "cont9_hr_min.drop(['Average OT'],axis=1)\n",
        "cont9_hr_min['Average OT']=l_time11n"
      ],
      "metadata": {
        "id": "Qg_I0_VpZ5f6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if len(cont8_hr_min['Designation'])>1:\n",
        "  cont8_hr_min_list = list(cont8_hr_min['Designation'])\n",
        "  cont8_hr_min_list2 = list(cont8_hr_min['Total OT_Days'])\n",
        "  plt.figure(figsize=(15, 11))  \n",
        "  plt.bar(cont8_hr_min_list, cont8_hr_min_list2,color = [\"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)]) for i in range(len(cont8_hr_min['Designation']))])\n",
        "  addlabels(cont8_hr_min_list, cont8_hr_min_list2)\n",
        "  plt.title('Designation wise total OT days')\n",
        "  plt.xticks(cont8_hr_min_list, rotation ='vertical')\n",
        "  plt.ylabel('Total OT Days')\n",
        "  plt.subplots_adjust(bottom = 0.15)\n",
        "  plt.savefig('des.png',bbox_inches=\"tight\")\n",
        "\n",
        "\n",
        "if len(cont9_hr_min['Designation'])>1:\n",
        "  cont9_hr_min_list = list(cont9_hr_min['Designation'])\n",
        "  cont9_hr_min_list2 = list(cont9_hr_min['Total OT'])\n",
        "  plt.figure(figsize=(15, 11))  \n",
        "  plt.bar(cont9_hr_min_list[::-1], cont9_hr_min_list2[::-1],color = [\"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)]) for i in range(len(cont9_hr_min['Designation']))])\n",
        "  addlabels(cont9_hr_min_list[::-1], cont9_hr_min_list2[::-1])\n",
        "  plt.title('Designation wise total OT')\n",
        "  plt.xticks(cont9_hr_min_list, rotation ='vertical')\n",
        "  plt.ylabel('Total OT')\n",
        "  plt.subplots_adjust(bottom = 0.15)\n",
        "  plt.savefig('des2.png',bbox_inches=\"tight\")\n"
      ],
      "metadata": {
        "id": "UNFIpGjQ-hXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cont11=result_5.sort_values(by=['Total OT_Days'], ascending=False)"
      ],
      "metadata": {
        "id": "bWHCRMuHe8Ar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cont11_hr_min=cont11.copy(deep=True)\n",
        "l_time13=[]\n",
        "l_time13n=[]\n",
        "\n",
        "for i in cont11_hr_min.index:\n",
        "      minutes, hours = math.modf(cont11_hr_min['Total OT'][i])\n",
        "      minutes*=100\n",
        "      ot_time = \"{:.0f} Hr {:.0f} Min\".format(hours, minutes)\n",
        "      l_time13.append(ot_time)\n",
        "\n",
        "      minutesn, hoursn = math.modf(cont11_hr_min['Average OT'][i])\n",
        "      minutesn*=100\n",
        "      ot_timen = \"{:.0f} Hr {:.0f} Min\".format(hoursn, minutesn)\n",
        "      l_time13n.append(ot_timen)\n",
        "cont11_hr_min.drop(['Total OT'],axis=1)\n",
        "cont11_hr_min['Total OT']=l_time13\n",
        "\n",
        "cont11_hr_min.drop(['Average OT'],axis=1)\n",
        "cont11_hr_min['Average OT']=l_time13n"
      ],
      "metadata": {
        "id": "-1cMiGLfe8Ax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sorting dataframe in descending order on basis of Total OT (User can get top x employees on basis of Total OT)\n",
        "cont10=result_5.sort_values(by=['Total OT'], ascending=False)"
      ],
      "metadata": {
        "id": "I45xxXLadqSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cont10_hr_min=cont10.copy(deep=True)\n",
        "l_time12=[]\n",
        "l_time12n=[]\n",
        "\n",
        "for i in cont10_hr_min.index:\n",
        "      minutes, hours = math.modf(cont10_hr_min['Total OT'][i])\n",
        "      minutes*=100\n",
        "      ot_time = \"{:.0f} Hr {:.0f} Min\".format(hours, minutes)\n",
        "      l_time12.append(ot_time)\n",
        "\n",
        "      minutesn, hoursn = math.modf(cont10_hr_min['Average OT'][i])\n",
        "      minutesn*=100\n",
        "      ot_timen = \"{:.0f} Hr {:.0f} Min\".format(hoursn, minutesn)\n",
        "      l_time12n.append(ot_timen)\n",
        "cont10_hr_min.drop(['Total OT'],axis=1)\n",
        "cont10_hr_min['Total OT']=l_time12\n",
        "\n",
        "cont10_hr_min.drop(['Average OT'],axis=1)\n",
        "cont10_hr_min['Average OT']=l_time12n"
      ],
      "metadata": {
        "id": "bRHSYjUXdqSw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if len(cont11_hr_min['Location'])>1:\n",
        "  cont11_hr_min_list = list(cont11_hr_min['Location'])\n",
        "  cont11_hr_min_list2 = list(cont11_hr_min['Total OT_Days'])\n",
        "  plt.figure(figsize=(10, 8))  \n",
        "  plt.bar(cont11_hr_min_list, cont11_hr_min_list2,color = [\"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)]) for i in range(len(cont11_hr_min['Location']))])\n",
        "  addlabels(cont11_hr_min_list, cont11_hr_min_list2)\n",
        "  plt.title('Location wise total OT days')\n",
        "  plt.xticks(cont11_hr_min_list, rotation ='vertical')\n",
        "  plt.ylabel('Total OT Days')\n",
        "  plt.subplots_adjust(bottom = 0.15)\n",
        "  plt.savefig('loc.png',bbox_inches=\"tight\")\n",
        "\n",
        "\n",
        "if len(cont10_hr_min['Location'])>1:\n",
        "  cont10_hr_min_list = list(cont10_hr_min['Location'])\n",
        "  cont10_hr_min_list2 = list(cont10_hr_min['Total OT'])\n",
        "  plt.figure(figsize=(10, 8))  \n",
        "  plt.bar(cont10_hr_min_list[::-1], cont10_hr_min_list2[::-1],color = [\"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)]) for i in range(len(cont10_hr_min['Location']))])\n",
        "  addlabels(cont10_hr_min_list[::-1], cont10_hr_min_list2[::-1])\n",
        "  plt.title('Location wise total OT')\n",
        "  plt.xticks(cont10_hr_min_list, rotation ='vertical')\n",
        "  plt.ylabel('Total OT')\n",
        "  plt.subplots_adjust(bottom = 0.15)\n",
        "  plt.savefig('loc2.png',bbox_inches=\"tight\")\n"
      ],
      "metadata": {
        "id": "ga54vaII_qfV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cont13=result_6.sort_values(by=['Total OT_Days'], ascending=False)"
      ],
      "metadata": {
        "id": "D5jTYhJ0wLQK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cont13_hr_min=cont13.copy(deep=True)\n",
        "l_time15=[]\n",
        "l_time15n=[]\n",
        "\n",
        "for i in cont13_hr_min.index:\n",
        "      minutes, hours = math.modf(cont13_hr_min['Total OT'][i])\n",
        "      minutes*=100\n",
        "      ot_time = \"{:.0f} Hr {:.0f} Min\".format(hours, minutes)\n",
        "      l_time15.append(ot_time)\n",
        "\n",
        "      minutesn, hoursn = math.modf(cont13_hr_min['Average OT'][i])\n",
        "      minutesn*=100\n",
        "      ot_timen = \"{:.0f} Hr {:.0f} Min\".format(hoursn, minutesn)\n",
        "      l_time15n.append(ot_timen)\n",
        "cont13_hr_min.drop(['Total OT'],axis=1)\n",
        "cont13_hr_min['Total OT']=l_time15\n",
        "\n",
        "cont13_hr_min.drop(['Average OT'],axis=1)\n",
        "cont13_hr_min['Average OT']=l_time15n"
      ],
      "metadata": {
        "id": "xQXKlQPnwLQP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sorting dataframe in descending order on basis of Total OT (User can get top x employees on basis of Total OT)\n",
        "cont12=result_6.sort_values(by=['Total OT'], ascending=False)"
      ],
      "metadata": {
        "id": "0DVjRXaawLQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cont12_hr_min=cont12.copy(deep=True)\n",
        "l_time14=[]\n",
        "l_time14n=[]\n",
        "\n",
        "for i in cont12_hr_min.index:\n",
        "      minutes, hours = math.modf(cont12_hr_min['Total OT'][i])\n",
        "      minutes*=100\n",
        "      ot_time = \"{:.0f} Hr {:.0f} Min\".format(hours, minutes)\n",
        "      l_time14.append(ot_time)\n",
        "\n",
        "      minutesn, hoursn = math.modf(cont12_hr_min['Average OT'][i])\n",
        "      minutesn*=100\n",
        "      ot_timen = \"{:.0f} Hr {:.0f} Min\".format(hoursn, minutesn)\n",
        "      l_time14n.append(ot_timen)\n",
        "cont12_hr_min.drop(['Total OT'],axis=1)\n",
        "cont12_hr_min['Total OT']=l_time14\n",
        "\n",
        "cont12_hr_min.drop(['Average OT'],axis=1)\n",
        "cont12_hr_min['Average OT']=l_time14n"
      ],
      "metadata": {
        "id": "XChhSMlGwLQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install xlsxwriter\n",
        "!pip install xlutils"
      ],
      "metadata": {
        "id": "1DD4DnB7MIup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openpyxl import Workbook\n",
        "import xlsxwriter\n",
        "import os\n",
        "\n",
        "def excelWriter():\n",
        "  workbook = xlsxwriter.Workbook(r'OT_Analysis.xlsx')\n",
        "  with pd.ExcelWriter(r'OT_Analysis.xlsx') as writer:\n",
        "  #writer = r\"C:\\Users\\Kartikey\\Desktop\\shorttt.xlsx\"\n",
        "  # write dataframe to excel\n",
        "      df_final_hr_min.to_excel(writer,sheet_name='OT')\n",
        "      result_hr_min.to_excel(writer,sheet_name='Total_OT')\n",
        "      cont2_hr_min.to_excel(writer,sheet_name='Highest_Total_OT_Days')\n",
        "      cont3_hr_min.to_excel(writer,sheet_name='Highest_Total_OT')\n",
        "      l_diff_hr_min.to_excel(writer,sheet_name='Exceeding OT Limit')\n",
        "      dfff_10.to_excel(writer,sheet_name='Exceeding 10 cons. OT days')\n",
        "      l_double_shift.to_excel(writer,sheet_name='Double shift')\n",
        "      cont4_hr_min.to_excel(writer,sheet_name='Operation_Highest_Total_OT_Days')\n",
        "      cont5_hr_min.to_excel(writer,sheet_name='Operation_Highest_Total_OT')\n",
        "      cont6_hr_min.to_excel(writer,sheet_name='Division_Highest_Total_OT_Days')\n",
        "      cont7_hr_min.to_excel(writer,sheet_name='Division_Highest_Total_OT')\n",
        "      cont8_hr_min.to_excel(writer,sheet_name='Desig_Highest_Total_OT_Days')\n",
        "      cont9_hr_min.to_excel(writer,sheet_name='Desig_Highest_Total_OT')\n",
        "      cont11_hr_min.to_excel(writer,sheet_name='Location_Highest_Total_OT_Days')\n",
        "      cont10_hr_min.to_excel(writer,sheet_name='Location_Highest_Total_OT')\n",
        "      cont13_hr_min.to_excel(writer,sheet_name='Dept_Highest_Total_OT_Days')\n",
        "      cont12_hr_min.to_excel(writer,sheet_name='Dept_Highest_Total_OT')\n",
        "\n",
        "with ft.ThreadPoolExecutor() as executor:\n",
        "  executor.submit(excelWriter).result()"
      ],
      "metadata": {
        "id": "-XC5EpaTKKZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pnglist=['doubleshiftgraph.png','doubleshiftgraph2.png','doubleshiftgraph3.png','doubleshiftgraph4.png','otlimit.png','otlimit2.png','cons.png','cons2.png','cons3.png','opr.png','opr2.png','div.png','div2.png','des.png','des2.png','loc.png','loc2.png']"
      ],
      "metadata": {
        "id": "F2l0IzpXyr_b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openpyxl import Workbook\n",
        "import xlsxwriter\n",
        "import os\n",
        "\n",
        "workbook = xlsxwriter.Workbook('Bar Graph-Visualization.xlsx')\n",
        "worksheet = workbook.add_worksheet('Double Shift')\n",
        "worksheet2 = workbook.add_worksheet('OT Limit')\n",
        "worksheet3 = workbook.add_worksheet('Consecutive 10 days OT')\n",
        "worksheet4 = workbook.add_worksheet('operation')\n",
        "worksheet5 = workbook.add_worksheet('division')\n",
        "worksheet6 = workbook.add_worksheet('designation')\n",
        "worksheet7 = workbook.add_worksheet('location')\n",
        "\n",
        "worksheet.insert_image('A2', 'doubleshiftgraph.png')\n",
        "worksheet.insert_image('R2', 'doubleshiftgraph2.png')\n",
        "worksheet.insert_image('A40', 'doubleshiftgraph3.png')\n",
        "worksheet.insert_image('R40', 'doubleshiftgraph4.png')\n",
        "worksheet2.insert_image('A2', 'otlimit.png')\n",
        "worksheet2.insert_image('R2', 'otlimit2.png')\n",
        "worksheet3.insert_image('A2', 'cons.png')\n",
        "worksheet3.insert_image('R2', 'cons2.png')\n",
        "worksheet3.insert_image('A40', 'cons3.png')\n",
        "worksheet4.insert_image('A2', 'opr.png')\n",
        "worksheet4.insert_image('R2', 'opr2.png')\n",
        "worksheet5.insert_image('A2', 'div.png')\n",
        "worksheet5.insert_image('X2', 'div2.png')\n",
        "worksheet6.insert_image('A2', 'des.png')\n",
        "worksheet6.insert_image('X2', 'des2.png')\n",
        "worksheet7.insert_image('A2', 'loc.png')\n",
        "worksheet7.insert_image('R2', 'loc2.png')\n",
        "workbook.close()"
      ],
      "metadata": {
        "id": "BYcVtGhDbp5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in pnglist:\n",
        "  if os.path.isfile(i):\n",
        "    os.remove(i)\n",
        "  else:\n",
        "    continue"
      ],
      "metadata": {
        "id": "iR0vfH-zyu_f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}